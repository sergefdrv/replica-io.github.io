<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>Replica_IO Blog</title>
        <link>https://replica-io.dev/blog</link>
        <description>Replica_IO Blog</description>
        <lastBuildDate>Tue, 27 Aug 2024 00:00:00 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[On Frameworks for Implementing Distributed Protocols]]></title>
            <link>https://replica-io.dev/blog/2024/08/27/on-frameworks-for-implementing-distributed-protocols</link>
            <guid>https://replica-io.dev/blog/2024/08/27/on-frameworks-for-implementing-distributed-protocols</guid>
            <pubDate>Tue, 27 Aug 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[A post concluding exploration of 7 frameworks for implementing distributed protocols.]]></description>
            <content:encoded><![CDATA[<p>This post concludes the second phase of the <a href="https://github.com/replica-io/replica-io/issues/7" target="_blank" rel="noopener noreferrer">state-of-the-art exploration</a> in the scope of milestone <a href="https://github.com/replica-io/replica-io/milestone/1" target="_blank" rel="noopener noreferrer">M0.1</a> of the Replica_IO project, namely exploration of existing frameworks for implementing distributed protocols. It shares the main conclusions drawn from exploring 7 different frameworks.</p>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>A companion video is available <a href="https://youtu.be/oRQG6EBzVe4" target="_blank" rel="noopener noreferrer">here</a>.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="exploring-distributed-protocol-frameworks">Exploring Distributed Protocol Frameworks<a href="https://replica-io.dev/blog/2024/08/27/on-frameworks-for-implementing-distributed-protocols#exploring-distributed-protocol-frameworks" class="hash-link" aria-label="Direct link to Exploring Distributed Protocol Frameworks" title="Direct link to Exploring Distributed Protocol Frameworks">​</a></h2>
<p>Trying to make a real breakthrough, such as what the Replica_IO project aims at, it is important to learn from prior attempts to deal with the problem. Having explored how real-world code bases typically implement the core distributed protocols like consensus and having summarized the findings in <a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols" target="_blank" rel="noopener noreferrer">the previous post</a>, I continued the exploration by surveying existing attempts to find a better approach to the problem, i.e. different frameworks for implementing distributed protocols.</p>
<p>I looked at the documentation and examples provided by each of the frameworks, as well as into their implementation, in order to figure out how they model and structure distributed systems, what kind of notation is used to specify and implement distributed protocols in those frameworks, what is their approach to communication, concurrency, and composition of protocol components, and what they offer for ensuring the correctness of protocols and their implementations.</p>
<p>After having explored each of the frameworks, I summarized and shared some of my findings. You can find those overviews on <a href="https://github.com/replica-io/replica-io/wiki/State-of-the-art-exploration" target="_blank" rel="noopener noreferrer">this wiki page</a>.</p>
<p>Here is the full list of 7 frameworks, based on different programming languages, that I explored<sup><a href="https://replica-io.dev/blog/2024/08/27/on-frameworks-for-implementing-distributed-protocols#user-content-fn-other-frameworks-ef0b52" id="user-content-fnref-other-frameworks-ef0b52" data-footnote-ref="true" aria-describedby="footnote-label">1</a></sup>:</p>
<ul>
<li><a href="https://github.com/consensus-shipyard/mir" target="_blank" rel="noopener noreferrer">Mir</a> — a framework for implementing, debugging, and analyzing distributed protocols (based on Go);</li>
<li><a href="https://github.com/SecureSolutionsLab/Atlas" target="_blank" rel="noopener noreferrer">Atlas</a> — a modular framework for building distributed mechanisms focused on configurability and performance (based on Rust);</li>
<li><a href="https://github.com/pfouto/babel-core" target="_blank" rel="noopener noreferrer">Babel</a> — a generic framework for implementing and executing distributed protocols (based on Java);</li>
<li><a href="https://distal.github.io/" target="_blank" rel="noopener noreferrer">DiStaL</a> — a framework for implementing and executing distributed protocols (based on Scala);</li>
<li><a href="https://github.com/dzufferey/psync" target="_blank" rel="noopener noreferrer">PSync</a> — a framework for implementing and verifying fault-tolerant distributed protocols (based on Scala);</li>
<li><a href="https://github.com/DistributedComponents/disel" target="_blank" rel="noopener noreferrer">Disel</a> — a framework for implementation and compositional machine-assisted verification of distributed systems and their clients (based on Coq);</li>
<li><a href="https://github.com/uwplse/verdi" target="_blank" rel="noopener noreferrer">Verdi</a> — a framework for implementing and formally verifying distributed systems (based on Coq).</li>
</ul>
<p>In the subsequent sections, I will share some of the observations and conclusions I made while exploring those frameworks. I decided to structure the discussion around the following aspects:</p>
<ul>
<li><em>model</em>: how distributed systems and their components are modeled;</li>
<li><em>structure</em>: how distributed protocol components are structured and composed together;</li>
<li><em>notation</em>: what kind of notation is used to specify and implement distributed protocols;</li>
<li><em>operation</em>: how distributed protocol components are executed and interact with each other;</li>
<li><em>verification</em>: how distributed protocols and their implementations are verified for correctness.</li>
</ul>
<p>But before we go into details, I would like to note that most of those frameworks were purely academic efforts and almost all of them seem to be abandoned now; unfortunately, they didn't seem to have found practical use. Nevertheless, it was good to learn from them. Let's now dive in.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="model">Model<a href="https://replica-io.dev/blog/2024/08/27/on-frameworks-for-implementing-distributed-protocols#model" class="hash-link" aria-label="Direct link to Model" title="Direct link to Model">​</a></h2>
<p>The way that systems and their components are modeled has a profound effect on the structure and shape of their specifications and implementation, on the operational aspects and verification for correctness. We can consider different levels of abstraction when modeling distributed systems: the high-level model of the system as a whole, the model of individual nodes within the system, as well as individual protocols and components within the nodes. Let's take a look at how the explored frameworks model distributed systems and their components.</p>
<p>The common approach is to model distributed systems at high level as <a href="https://en.wikipedia.org/wiki/Transition_system" target="_blank" rel="noopener noreferrer">state transition systems</a> where the global system state changes upon external and internal events, such as client requests, messages exchanged within the system, and timeouts. In this model, the global system state includes the states of all individual nodes and their components, as well as the environment state. The environment state usually includes the state of the network the nodes communicate through, in particular the messages in transit. Transitioning from one state to another happens according to a global <em>transition function</em> triggered by events. The transition function receives the current state of the system together with the triggering event and returns the new system state.</p>
<p>The explored frameworks follow the <a href="https://en.wikipedia.org/wiki/Message_passing" target="_blank" rel="noopener noreferrer">message-passing</a> approach, where the states of individual nodes and protocol components are disjoint, i.e. different parts do not share pieces of state. Interaction between nodes happens through the network by sending and receiving messages. Sending and receiving of messages are modeled as events modifying the global system state by updating the set of messages in transit in the network state and, in case of message receiving, the state of the target component in the destination node. For example, in Disel, the system state includes a "message soup" for each protocol, which models the current state and the history of the network.&nbsp;In Disel's abstract model, messages are&nbsp;never removed&nbsp;from the message soup, instead they are marked either as active or consumed.</p>
<p>Nodes and network failures are modeled as special events, e.g. dropping or duplicating messages in the network, disabling normal event handling in faulty nodes or (partially) resetting their state. Some of the frameworks only consider crash faults, leaving <a href="https://en.wikipedia.org/wiki/Byzantine_fault" target="_blank" rel="noopener noreferrer">Byzantine faults</a> for the future work. The system models in most of the frameworks do not seem to include timing assumption, so they can be considered asynchronous. In contrast, PSync employs the Heard-Of model based on communication-closed rounds, which provides an illusion of simple synchronous communication on top of the partial synchrony of the actual underlying network. In this model, protocol execution proceeds in explicit rounds, alternating communication with protocol state transition based on the set of messages received during the round. Network and node faults in this model are unified, and the network assumptions are specified in terms of the heard-of sets.</p>
<p>Communication between nodes is predominantly modeled as fire-and-forget message delivery, where messages can be reordered or dropped by the network abstraction. Though, in Verdi, protocols are first modeled with an idealistic, reliable network semantics, which can then be translated&nbsp;into weaker fault models using&nbsp;verified system transformers. Babel allows modeling protocols in stronger communication models using communication channel abstractions, which represent communication mechanisms with different properties and guarantees.</p>
<p>Individual components within nodes are commonly modeled as sequential, event-driven state machines interacting with each other via reliable message passing. The message passing normally follows the one-to-one one-way or request-response patterns; however, some of the frameworks also support one-to-many notifications between components. Some frameworks (e.g., Verdi) explicitly distinguish between the events that are external to the distributed protocol, like client requests, and internal events, like exchanging messages between protocol components and nodes within the distributed system.</p>
<p>To overcome the limitations of strict state separation between protocol components in the abstract model, Disel allows coupling protocols via inter-protocol behavioral dependencies, called send-hooks, which allow restricted logical access to other protocol's state. Disel doesn't seem to strictly follow the message-passing model for protocol components within the same node, supporting generic composition of protocol components. Disel also provides mechanisms to establish stronger properties of protocols and their combinations by strengthening them with additional inductive invariants.</p>
<p>As we can see, although there are some interesting variations and extensions, the underlying system model in the explored frameworks is largely the same, namely the one of a state transition system composed of components, which are sequential, event-driven state machines with disjoint state, interacting via message passing. This is remarkably similar to how distributed protocols are usually implemented in real-world code bases, which do not use any framework, as I described in <a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols" target="_blank" rel="noopener noreferrer">the previous post</a>. This approach tends to shift the focus more to the operational rather than functional and logical aspects of the system. There I also pointed out, when discussing how protocol implementations attempt to <a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#evading-concurrency" target="_blank" rel="noopener noreferrer">evade concurrency</a>, that this approach may complicate the implementation and cause fragmentation of the protocol logic. Perhaps, adopting the same kind of the underlying model is one of the reasons why the explored frameworks do not seem to have made a real breakthrough in designing and implementing distributed protocols.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="structure">Structure<a href="https://replica-io.dev/blog/2024/08/27/on-frameworks-for-implementing-distributed-protocols#structure" class="hash-link" aria-label="Direct link to Structure" title="Direct link to Structure">​</a></h2>
<p>In all of the explored frameworks, protocol implementations rely on some kind of runtime or shim provided by the framework, hiding low-level concerns from implementation of the protocol logic. In most of the frameworks, the runtime is responsible for coordinating the execution of protocol components and interaction between them; some of the frameworks also provide there dedicated interfaces for communication over the network and setting timers. Protocol components normally need to be registered within the runtime before they can function within the system.</p>
<p>In most cases, protocol components within the same node can interact by simply sending some kind of internal messages to each other, without establishing any explicit connection. In contrast, components in Atlas require explicit orchestration of the interaction with the rest of the system. Disel instead supports composition of components expressed as effectful functional programs; it also allows loosely coupling protocol components via inter-protocol behavioral dependencies, called send-hooks, at the formal specification level.</p>
<p>Since the runtime in Mir is only responsible for coordinating the execution of protocol components and interaction between them, there are special components that provide functionality for sending and receiving messages over the network, as well as for setting local timers and for cryptographic operations. Mir explicitly distinguishes between passive components, which can only produce events synchronously, as a result of processing input events provided by the runtime, and active components, which can asynchronously produce new events on their own.</p>
<p>There are frameworks that provide means for enhancing protocol components with additional properties. Disel provides a protocol combinator&nbsp;<code>ProtocolWithIndInv</code>, which&nbsp;allows elaborating a protocol by strengthening it with additional inductive invariants. Verdi provides verified system transformers, which allow transforming protocols specified, implemented, and verified in an idealistic, reliable network semantics into an equivalent implementation, preserving the transformed system properties under a weaker fault model. PSync provides a class, which can be used to wrap protocol round instances to support updating progress conditions and synchronizing rounds in a Byzantine setting.</p>
<p>There are two main approaches to structure interaction of distributed protocols with the rest of the application. Some frameworks provide a mechanism for interacting with protocol components by sending and receiving messages, same as protocol components interact with each other. Other frameworks allow defining dedicated interfaces for that purpose, featuring callable methods or special IO events. In some of the frameworks, protocol components are supplied with some kind of handles to trigger side effects, such as sending messages or setting up timers; in other frameworks, side effects only happen after returning the control back to the runtime, e.g. through the return value or using a monadic structure.</p>
<p>Protocol components commonly consist of the component's state and protocol logic structured as handlers modifying the state or state transition functions, which are triggered by the runtime upon certain events or conditions. In Distal and Disel, the handlers/transitions can be augmented with guarding conditions that must hold in order to trigger the action.</p>
<p>The round-based model in PSync imposes a particular structure of protocol components. Protocol components in PSync must specify a sequence of protocol rounds. Each round, in general, consists of methods to: initialize the round, send messages at the beginning of the round, process received messages, and finally update the internal state before transitioning into the next round.</p>
<p>PSync and Disel explicitly separate the protocol specification from its implementation, whereby the specification is used to formally verify the implementation. Protocol specifications in PSync consist of protocol properties, as well as safety and liveness predicates (assumptions). In order to aid automated verification in PSync, the specification should also include round and/or phase invariants; round transition relations are automatically derived from the code, although this imposes certain limitations on the code. In Disel, high-level abstract protocol specifications are defined in terms of state-space coherence predicates and send/receive transitions.</p>
<p>The configuration of protocol components within nodes and their internal structure can be more static or dynamic. For example, in Babel, protocol components and various components' callbacks are registered within the runtime dynamically. The configuration of top-level components in Mir is rather static, for it cannot be changed after initialization, but there is a special component, called factory module, that supports creating sub-components dynamically. Such flexibility at runtime can make formal verification particularly hard, so the frameworks focused on formal verification (PSync, Disel, and Verdi) tend to be rather static with respect to the configuration and internal structure of protocol components.</p>
<p>Overall, the abstract model adopted by a framework, e.g. the model of a generic state transition system with message-passing or the Heard-Of model based on communication-closed rounds, largely determines how protocol specifications and implementations are structured within the framework. The framework's features like formal verification can add further restrictions, e.g. restricting runtime flexibility of the configuration and internal structure of protocol components.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="notation">Notation<a href="https://replica-io.dev/blog/2024/08/27/on-frameworks-for-implementing-distributed-protocols#notation" class="hash-link" aria-label="Direct link to Notation" title="Direct link to Notation">​</a></h2>
<p>All of the explored frameworks use the general-purpose programming language they are based on as the primary means for expressing protocol implementations. To enhance ergonomics and expressiveness, most of the frameworks introduce some notational extensions, e.g. elements of an embedded domain-specific language (eDSL).</p>
<p>Using a regular general-purpose programming language as the basis allows tapping directly into the comprehensive features of the language, such as the type system, polymorphism, inheritance, and metaprogramming. On the other hand, implementing protocol components in regular code can produce some undesirable effects such as nondeterminism, e.g. when iterating over built-in unordered data structures, which is problematic for reproducible simulation-based testing. For that reason, Mir provides some utility functions that should be used in place of usual idiomatic code to avoid that kind of nondeterminism. Rich expressiveness of general-purpose languages can also make automatic verification difficult, e.g. PSync is quite limited in what kind of Scala constructs it supports in automatic derivation of transition relations from the code.</p>
<p>In most cases, the notational extensions introduced by the frameworks serve to make the code more declarative and concise. One target of such enhancements is providing a convenient and clear way of expressing the typical event-oriented pseudo-code notation with <code>upon</code> statements. For example, the protocol logic in Distal is implemented by defining rules and the corresponding actions, whereby the rules are expressed in a declarative style resembling typical pseudo-code found in the literature and specify event predicates, such as the message type and matching conditions, as well as the means to specify composite events, which are triggered by collections of messages.</p>
<p>Another area of applying notational enhancements is for expressing certain actions performed by the protocol logic and overcoming the limitations of the host language. For example, Distal provides a special notation for sending messages, discarding received messages, as well as for scheduling actions to be executed in future. Disel extends Coq's specification language Gallina with effectful commands (actions), such as sending and receiving messages, reading from local state, monadic sequential composition, and general recursion. For message sending and receiving actions, Disel provides transition wrappers, which lift low-level operations on the networking layer to the level of well-typed program primitives corresponding to the protocol specification. Similarly, Verdi provides a monad for expressing the actions of sending messages, emitting output event, and manipulating the current state, as well as convenience notation for various monadic bindings.</p>
<p>Finally, expressing protocol properties, assumptions, and invariants, as well as the related annotations in the protocol implementation can also benefit from notational enhancements. PSync, for instance, defines a DSL for expressing properties, predicates and invariants, in which one of the main primitives is the notion of domain, representing a set of values of certain type with universal and existential quantification defined for it, as well as set comprehension. Disel features a special notation for representing the higher-order Hoare types of program fragments.</p>
<p>Many elements of a DSL can be implemented using common programming language techniques like polymorphism, inheritance, composition, higher-order functions, and the type system features. This way, Distal implements most of its DSL as ordinary methods and convenience aliases. However, this approach has certain limitations, and such techniques as metaprogramming (macros) or code generation are often required. For instance, in Distal, the key element of the DSL is implemented as a macro; in PSync, automatic derivation of transition relations from the code is also implemented as a macro. Code generation in Mir reduces the amount of hand-written boilerplate code by processing Protobuf definitions annotated with special extensions. Disel and Verdi take advantage of Coq's syntax extension features.</p>
<p>Clear and convenient notation for defining protocol specifications and their implementation is crucial for ergonomics and expressiveness. Building upon ordinary code, clever use of common programming language techniques, such as polymorphism, inheritance, composition, higher-order functions, and the type system features, should be the preferred approach for achieving notational expressiveness. Such techniques as metaprogramming and code generation can greatly help overcoming the limitations of that approach or further improving the notation, but they can make the framework more complicated and, therefore, should be employed judiciously.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="operation">Operation<a href="https://replica-io.dev/blog/2024/08/27/on-frameworks-for-implementing-distributed-protocols#operation" class="hash-link" aria-label="Direct link to Operation" title="Direct link to Operation">​</a></h2>
<p>In terms of operation, the core part in most of the frameworks is some kind of runtime or engine that orchestrates the execution of protocol components and their interaction. For concurrent execution of protocol components, the runtimes mostly rely on conventional concurrency mechanisms used in the corresponding language's ecosystem, such as goroutines in Go and execution pools in Java and Scala. Atlas, notably, is based on native OS threads rather than an async Rust runtime like Tokio, presumably due to a performance overhead of the latter.</p>
<p>There are two main approaches to implementing interaction based on message-passing between protocol components and with the networking layer: using a central event dispatching loop or through explicit channels established between components. Mir is a good example of the former approach, whereas Atlas follows the latter one. Since different protocol components normally operate asynchronously, there is often some kind of event queue or buffer placed between the components to accommodate for the asynchrony.</p>
<p>This raises an issue of preventing unbounded growth of those queues. Mir addresses this problem by temporarily blocking the influx of external events from active modules when the amount of events buffered in internal queues exceeds certain thresholds. Atlas relies on flow control provided by bounded buffered channels for communication between components.</p>
<p>In general, garbage collection issue is an important aspect of operation in distributed protocol implementations. Sometimes it can happen automatically, e.g. in PSync, received message sets are automatically discarded by the runtime upon transitioning into a new round. However, in some cases, it requires special care. For example, in Distal, protocol components should explicitly discard automatically buffered messages that become irrelevant for further execution of the protocol, in order to avoid unbounded growth of state and slowing down evaluation of rules. In Mir, there is an interesting pattern for performing garbage collection of internal component's state, whereby each disposable piece of state is assigned a numerical retention index, and the component removes the pieces of state whose retention index is below a specified value upon processing a dedicated garbage collection event emitted by another component.</p>
<p>Communication between nodes in most of the frameworks is implemented in a simplistic manner, providing best-effort message delivery, following the fire-and-forget communication style. Babel is a notable exception, since it introduces a notion of communication channel abstraction, where different channel types can represent different communication mechanisms with different properties and guarantees, e.g. more reliable message delivery, multiplexing connections, and φ-accrual failure detection.</p>
<p>So orchestrating the execution and coordinating interaction of protocol components often require some kind of runtime provided by the framework. The runtime should take care of asynchrony, garbage collection, communication, and coordination within the node, preventing unbounded growth of internal state and ensuring good performance.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="verification">Verification<a href="https://replica-io.dev/blog/2024/08/27/on-frameworks-for-implementing-distributed-protocols#verification" class="hash-link" aria-label="Direct link to Verification" title="Direct link to Verification">​</a></h2>
<p>Not all of the explored frameworks are concerned with verifying correctness of protocols and their implementations. Verification is the primary area of focus for Disel and Verdi, as well as PSync. Verification is not a major concern in Mir, though it provides some mechanisms that can be considered as lightweight verification of protocol implementation correctness.</p>
<p>Mir includes support for recording, inspecting, modifying, and replaying traces of events being passed by the node engine between the components, which can be very helpful for debugging, but also to perform correctness analysis. Mir also comes with a simple discrete-event simulation runtime that can be used for randomized reproducible testing with simulated time.</p>
<p>Full-fledged formal verification of protocol specifications and implementation in Disel and Verdi relies on machine-assisted theorem proving, whereas PSync attempts to automate the process. Theorem proving, even if machine-assisted, is a very difficult, time consuming task and requires special expertise. Automated verification, on the other hand, is in general undecidable and can only be achieved with certain restrictions to the system model and the protocol implementation.</p>
<p>Formal verification requires formal specification of the assumptions and the required properties. In Disel, protocol specifications are defined in terms of state-space coherence predicates and send/receive transitions. In Verdi, the correct behavior of the protocol is specified as a logical predicate over its possible traces of events. Formal specifications in PSync are expressed in terms of protocol properties, expressed in a fragment of a first-order temporal logic, as well as safety and liveness predicates (assumptions), expressed in terms of cardinalities of heard-of sets.</p>
<p>In these frameworks, the method of formally proving the correctness is typically by induction, constructing inductive state invariants. Coming up with appropriate inductive invariants constitutes the greatest difficulty in the verification effort and requires special skills.</p>
<p>In PSync, the simple round-based structure with lock-step semantics makes protocol implementation amenable to automated verification that can check safety and liveness properties. The verification, though, requires inductive invariants at the boundaries between rounds. However, the automated verification problem is decidable with certain constraints.</p>
<p>The correctness of protocol implementation in Verdi is proved directly, whereas Disel employs a different approach. For implementing protocol specification, Disel provides a DSL, embedded shallowly into Coq, that extends Coq's specification language Gallina. Disel programs and their fragments are assigned types corresponding to the protocol specification in higher-order separation-style Hoare logic. For message sending and receiving actions, Disel provides transition wrappers, which lift low-level operations on the networking layer to the level of well-typed program primitives corresponding to the protocol specification. Well-typed programs are guaranteed to be <em>correct by construction</em> w.r.t. the protocol specifications.</p>
<p>In Verdi, once the protocol is specified, implemented, and verified in an idealistic reliable network semantics, it can be translated using <em>verified system transformers</em> into an equivalent implementation, preserving the transformed system properties under a weaker fault model.</p>
<p>in Disel, protocol specifications can be generic and parameterized. The generic protocol specifications with their proven invariants can be used in composition. Disel provides mechanisms to establish stronger properties of generic protocols and their combinations by elaborating the protocol, i.e. strengthening it with additional inductive invariants.</p>
<p>Correctness is very important for the critical fault-tolerant protocols; therefore, the verification aspect deserves special attention. There are relatively easy-to-apply lightweight methods, such as randomized reproducible testing with discrete-event simulation, and there are sophisticated formal methods typically requiring special skills and expertise, such as machine-assisted theorem proving. However, some particularly structured system models may enable automated reasoning and make formal verification more practical, though at the cost of additional limitations.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusions">Conclusions<a href="https://replica-io.dev/blog/2024/08/27/on-frameworks-for-implementing-distributed-protocols#conclusions" class="hash-link" aria-label="Direct link to Conclusions" title="Direct link to Conclusions">​</a></h2>
<p>Having explored these 7 frameworks for implementing distributed protocols, I found most of them not sufficiently developed for practical use, though some of the ideas and techniques employed there were worth exploring. Being purely academic efforts, most of the frameworks seem to have been abandoned after exploring some ideas and publishing the results. As of time of this writing, Mir is perhaps the most mature, well documented, and up-to-date one among these frameworks.</p>
<p>Focusing on some particular aspects of implementing distributed protocols, such as unifying and standardizing components, testing and debugging, notational convenience, or formal verification, while mostly neglecting the remaining aspects, may be appropriate for academic research, but this is certainly not sufficient for achieving practical adoption. Moreover, the programming languages that most of the frameworks are based on would make it hard to integrate the protocol implementations directly into larger code bases written in other languages, let alone that having to learn a less commonly used language like Scala or Coq is an additional obstacle for adoption. Please refer to the <a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols" target="_blank" rel="noopener noreferrer">previous post</a> about practical aspects of implementing distributed protocols.</p>
<p>Most important, perhaps, is that all of the frameworks seem to basically adopt the same model of a state transition system and trying to mimic the event-oriented notation as found in typical pseudo-code with <code>upon</code> statements in the literature on distributed protocols. This largely impacts how protocol implementations are expressed and structured in those frameworks.</p>
<p>I believe, if we want to make a real breakthrough in <em>both designing and implementing</em> distributed protocols, which is what the Replica_IO project is about, then we should first of all be innovative, challenging the status quo, and think holistically, taking into account all relevant aspects. Trying to rethink the conventional distributed system model and the way of expressing distributed protocols would be a good start.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="next-steps">Next Steps<a href="https://replica-io.dev/blog/2024/08/27/on-frameworks-for-implementing-distributed-protocols#next-steps" class="hash-link" aria-label="Direct link to Next Steps" title="Direct link to Next Steps">​</a></h2>
<p>Having explored some distributed protocol implementations and frameworks for implementing distributed protocols, now it is a good time to clearly state the problems in designing and implementing distributed protocols to focus on for the rest of milestone <a href="https://github.com/replica-io/replica-io/milestone/1" target="_blank" rel="noopener noreferrer">M0.1</a> and start gathering ideas on how we could approach them. Apart from that, there are still some potentially related concepts, approaches, and techniques worth looking into as part of the initial state-of-the-art exploration. The exploration tasks are tracked in the scope of <a href="https://github.com/replica-io/replica-io/issues/7" target="_blank" rel="noopener noreferrer">this issue</a> on GitHub.</p>
<p>Once the initial exploratory stage is over, it will be time to come up with key ideas concerning core principles that will guide the process of designing and implementing generic components within the framework (milestone <a href="https://github.com/replica-io/replica-io/milestone/1" target="_blank" rel="noopener noreferrer">M0.1</a>). Then those ideas will be developed into clearly formulated concepts (milestone&nbsp;<a href="https://github.com/replica-io/replica-io/milestone/2" target="_blank" rel="noopener noreferrer">M0.2</a>), their feasibility will be verified with code (milestone&nbsp;<a href="https://github.com/replica-io/replica-io/milestone/3" target="_blank" rel="noopener noreferrer">M0.3</a>). After that, prototype, MVP, and production versions of the framework will be developed and released (milestones&nbsp;<a href="https://github.com/replica-io/replica-io/milestone/4" target="_blank" rel="noopener noreferrer">M1</a>, <a href="https://github.com/replica-io/replica-io/milestone/5" target="_blank" rel="noopener noreferrer">M2</a>, and <a href="https://github.com/replica-io/replica-io/milestone/6" target="_blank" rel="noopener noreferrer">M3</a>).</p>
<p>It does not mean at all that exploration, ideation, and prototyping will not take place at later stages; the milestones simply define the framework's general level of maturity. The framework will continuously evolve and expand and at some point become a de facto standard for implementing critical fault-tolerant systems providing a growing collection of easy-to-use reliable and efficient distributed replication mechanisms.</p>
<!-- -->
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37">❤️</span>Supporting</div><div class="admonitionContent_BuS1"><p>If you like the project and find it valuable, please <a href="https://github.com/sponsors/replica-io">support</a> its further development! 🙏</p></div></div>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>If you have any thought you would like to share or any question regarding this post, please add a comment <a href="https://github.com/orgs/replica-io/discussions/43" target="_blank" rel="noopener noreferrer">here</a>. You are also welcome to <a href="https://github.com/orgs/replica-io/discussions/new" target="_blank" rel="noopener noreferrer">start a new discussion</a> or chime in to <a href="https://discord.replica-io.dev/" target="_blank" rel="noopener noreferrer">our Discord</a> server.</p></div></div>
<!-- -->
<section data-footnotes="true" class="footnotes"><h2 class="anchor anchorWithStickyNavbar_LWe7 sr-only" id="footnote-label">Footnotes<a href="https://replica-io.dev/blog/2024/08/27/on-frameworks-for-implementing-distributed-protocols#footnote-label" class="hash-link" aria-label="Direct link to Footnotes" title="Direct link to Footnotes">​</a></h2>
<ol>
<li id="user-content-fn-other-frameworks-ef0b52">
<p>If you know of some other framework for implementing distributed protocols that I should have looked into, please let me know. <a href="https://replica-io.dev/blog/2024/08/27/on-frameworks-for-implementing-distributed-protocols#user-content-fnref-other-frameworks-ef0b52" data-footnote-backref="" aria-label="Back to reference 1" class="data-footnote-backref">↩</a></p>
</li>
</ol>
</section>]]></content:encoded>
            <author>sergefdrv@replica-io.dev (Sergey Fedorov)</author>
            <category>technical</category>
            <category>overview</category>
            <category>long</category>
        </item>
        <item>
            <title><![CDATA[On Implementation of Distributed Protocols]]></title>
            <link>https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols</link>
            <guid>https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols</guid>
            <pubDate>Mon, 04 Mar 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[A post concluding exploration of 14 notable distributed protocol implementations.]]></description>
            <content:encoded><![CDATA[<p>This post concludes the first phase of the <a href="https://github.com/replica-io/replica-io/issues/7" target="_blank" rel="noopener noreferrer">state-of-the-art exploration</a> in the scope of milestone <a href="https://github.com/replica-io/replica-io/milestone/1" target="_blank" rel="noopener noreferrer">M0.1</a> of the Replica_IO project, namely exploration of selected notable distributed protocol implementations. It shares the main conclusions drawn from exploring 14 different code bases and outlines the key areas of focus for the next steps developing the Replica_IO framework.</p>
<!-- -->
<!-- -->
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>A companion video is available <a href="https://youtu.be/Q6wW8NqtpGw" target="_blank" rel="noopener noreferrer">here</a>.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="exploring-distributed-protocol-implementations">Exploring Distributed Protocol Implementations<a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#exploring-distributed-protocol-implementations" class="hash-link" aria-label="Direct link to Exploring Distributed Protocol Implementations" title="Direct link to Exploring Distributed Protocol Implementations">​</a></h2>
<p>I believe that discovering neat, yet practical, solutions to complicated problems demands serious, deliberate preparation. Clearly, before being able to come up with such solutions, one first needs to acquire a deep understanding of the problem, identify the relevant aspects and requirements. It is also important to learn from prior attempts to deal with the problem. Otherwise, it would be naive to expect any significant advancement beyond the status quo.</p>
<p>Since Replica_IO aims at making a breakthrough in designing and implementing distributed protocols, I decided to start exploring the state of the art by selecting and looking into a number of notable distributed protocol implementations. Although I already had experience implementing such protocols myself, nevertheless, I decided to dive in and see for myself how others had approached this challenge. I wanted to learn from those projects, better understand the typical requirements and difficulties coming up in real-world use cases, and, perhaps, discover some interesting techniques or ideas along the way, as well as to identify the key areas of focus for the next steps.</p>
<p>So I onboarded myself into one code base after the other, as if I were to work on it. I was focused on the general structure of code, node-to-node communication mechanisms, the implementation details of the core protocols ensuring consistency between nodes, as well as mechanisms for monitoring and controlling execution of the protocol. I tried my best to understand <em>how</em> those protocols are structured and implemented. After having explored each of the code bases, I summarized and shared some of my findings. You can find those overviews on <a href="https://github.com/replica-io/replica-io/wiki/State-of-the-art-exploration" target="_blank" rel="noopener noreferrer">this wiki page</a>.</p>
<p>Here is the full list of the code bases, written in different programming languages, that I explored<sup><a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#user-content-fn-other-impl-d8d72b" id="user-content-fnref-other-impl-d8d72b" data-footnote-ref="true" aria-describedby="footnote-label">1</a></sup>:</p>
<ol>
<li><a href="https://github.com/tendermint/tendermint" target="_blank" rel="noopener noreferrer">Tendermint Core</a> / <a href="https://github.com/cometbft/cometbft" target="_blank" rel="noopener noreferrer">CometBFT</a> — a state machine replication engine (written in Go);</li>
<li><a href="https://github.com/etcd-io/raft" target="_blank" rel="noopener noreferrer">etcd Raft</a> — a library for maintaining replicated state machines (written in Go);</li>
<li><a href="https://github.com/aptos-labs/aptos-core/tree/aptos-cli-v1.0.13/consensus" target="_blank" rel="noopener noreferrer">AptosBFT</a> — a consensus component supporting state machine replication in the Aptos blockchain (written in Rust);</li>
<li><a href="https://github.com/bft-smart/library" target="_blank" rel="noopener noreferrer">BFT-SMaRt</a> — a library implementing BFT-SMaRt, a state machine replication system (written in Java);</li>
<li><a href="https://github.com/SmartBFT-Go/consensus" target="_blank" rel="noopener noreferrer">SmartBFT-Go</a> — a library implementing state machine replication inspired by BFT-SMaRt (written in Go);</li>
<li><a href="https://github.com/paritytech/substrate" target="_blank" rel="noopener noreferrer">Substrate</a> — a framework for building application-specific blockchains (written in Rust);</li>
<li><a href="https://github.com/sigp/lighthouse" target="_blank" rel="noopener noreferrer">Lighthouse</a> — an Ethereum consensus client (written in Rust);</li>
<li><a href="https://github.com/algorand/go-algorand" target="_blank" rel="noopener noreferrer">Algorand</a> — a blockchain based on the Algorand consensus protocol (written in Go);</li>
<li><a href="https://github.com/ava-labs/avalanchego" target="_blank" rel="noopener noreferrer">Avalanche</a> — a blockchain platform based on the Avalanche consensus protocol (written in Go);</li>
<li><a href="https://github.com/dfinity/ic" target="_blank" rel="noopener noreferrer">Internet Computer blockchain</a> (ICP) — a general-purpose blockchain system developed by the DFINITY Foundation (written in Rust);</li>
<li><a href="https://github.com/MystenLabs/sui" target="_blank" rel="noopener noreferrer">Sui</a> — a smart contract platform based on Narwhal and Bullshark protocols (written in Rust);</li>
<li><a href="https://github.com/apache/zookeeper" target="_blank" rel="noopener noreferrer">Apache ZooKeeper</a> — a distributed coordination, synchronization, and configuration service (written in Java);</li>
<li><a href="https://github.com/apache/kafka" target="_blank" rel="noopener noreferrer">Apache Kafka</a> — a distributed event streaming platform implementing a variant of the Raft consensus protocol (written in Java, integrated with Scala);</li>
<li><a href="https://github.com/input-output-hk/cardano-node" target="_blank" rel="noopener noreferrer">Cardano</a> — a blockchain platform based on the Ouroboros family of consensus protocols (written in Haskell).</li>
</ol>
<p>In the subsequent sections, I will share with you some of the observations and conclusions I made while exploring those code bases. I decided to structure the discussion around the following aspects of implementing distributed protocols:</p>
<ul>
<li><em>complexity</em>: what makes distributed protocols hard to reason about and implement;</li>
<li><em>correctness</em>: how to ensure that the implementation guarantees the requires properties;</li>
<li><em>resource utilization</em>: how to prevent ineffective expenditure of limited computing resources;</li>
<li><em>maintainability</em>: how to manage long-running distributed systems and diagnose issues;</li>
<li><em>flexibility</em>: how to achieve high adaptability, reusability, and evolvability of code.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="complexity">Complexity<a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#complexity" class="hash-link" aria-label="Direct link to Complexity" title="Direct link to Complexity">​</a></h2>
<p>Distributed, fault-tolerant protocols are notoriously hard to implement, and there are justifiable reasons for that. This is primarily because that kind of system consists of largely independent nodes communicating through potentially unstable, unreliable network; some of the nodes may fail in different ways. The protocol is required to tolerate, within a bound, such unfavorable conditions and keep working reliably. More than that, it is supposed to deliver decent performance using limited resources. All this adds a great deal of <em>inherent, essential complexity</em>, which we simply cannot remove without weakening our requirements.</p>
<p>However, when it comes to actually designing and implementing these protocols, there is also another kind of complexity: <em>incidental, non-essential complexity</em>. This kind of complexity, though being closely related, does not strictly belong to the problem. We incidentally introduce it because we are not aware of or fail to recognize a simpler way of solving the problem at hand.</p>
<p>Incidental complexity can start creeping in when trying to understand and interpret a protocol specification<sup><a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#user-content-fn-thinking-complexity-d8d72b" id="user-content-fnref-thinking-complexity-d8d72b" data-footnote-ref="true" aria-describedby="footnote-label">2</a></sup>, which is often too far from the realities of software engineering. Simply the way a protocol is specified can misguide the engineer trying to implement it and induce all sorts of difficulties. For example, pseudo-code in scientific papers is often defined in terms of global, unstructured variables and omits concurrency issues.</p>
<p>Implementing a distributed protocol in one of the conventional programming languages, chances are that the implementation will simply employ some general techniques commonly used in that language's ecosystem. Such general techniques may be very powerful and universal, but freely using this unconstrained power and flexibility, we can easily end up with a code base that is very hard to understand and maintain. For example, dealing with concurrency and synchronization using low-level primitives in the implementation of high-level protocol logic clutters the code and multiplies the complexity.</p>
<p>Haste is another great source of incidental complexity. There is always temptation to cut corners, especially when under time pressure. Imprudently copying approaches from elsewhere, adding temporary workarounds and ad hoc patches makes code entangled and poorly structured.</p>
<p>Using advanced features and sophisticated techniques can also add unnecessary complexity. Though this is ambivalent because it can actually help to express the implementation more conveniently and simplify the reasoning about it, but only when the advanced machinery is hidden behind a simple, clear, and easy to use interface.</p>
<p>It is pretty clear that introducing additional complexity is generally bad. But does it really matter? Couldn't we just implement the thing somehow, test it well, and simply tolerate the additional complexity? Well, surely, with rigorous testing, we can be sufficiently confident that our implementation is correct. However, in that case, making a small change, e.g. applying a simple fix to address a major issue discovered later can reportedly<sup><a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#user-content-fn-tendermint-liveness-fix-d8d72b" id="user-content-fnref-tendermint-liveness-fix-d8d72b" data-footnote-ref="true" aria-describedby="footnote-label">3</a></sup> take months of work. So it would be very hard to further improve, adapt, or reuse such implementation.</p>
<p>We need a structured, yet flexible enough, approach guiding us away from incidental complexity if we wish to avoid wasted efforts and foster innovation in the field. Let's look into more details concerning complexity in implementation of distributed protocols.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="modularity">Modularity<a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#modularity" class="hash-link" aria-label="Direct link to Modularity" title="Direct link to Modularity">​</a></h3>
<p>We can deal with a complex problem, such as implementing a distributed protocol, by dividing it into smaller, simpler problems, solving them individually, and then combining the solutions to finally address the original problem. This is, basically, what modularity is about. In this process, it is crucial how we divide the problem, what kind of pieces we get, and how we combine them back together.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="granularity">Granularity<a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#granularity" class="hash-link" aria-label="Direct link to Granularity" title="Direct link to Granularity">​</a></h4>
<p>First of all, modularity comes in different levels of <em>granularity</em>. Implementing a large component, such as a state machine replication engine, we can define its external dependencies, then split the component into several chunks of functionality and stop there. That is certainly better than having to deal with a complete monolith, but this level of modularity would still be too <em>coarse</em>. Instead, we can continue decomposing the sub-components further until we end up with reasonably small and simple, yet non-trivial, components; this is <em>fine</em> modularity.</p>
<p>All of the explored code bases exhibit some level of modularity. It is quite common to separate concerns by delegating pieces of functionality to external components. This way, most of the code bases clearly separate implementation of the protocol logic from such functionality as communication between nodes, producing and verifying cryptographic signatures, persistent storage, executing transactions on the replicated state, etc. Most of the implementations also separate dispatching of events, such as inbound messages, from their handling; there is typically a component responsible for classifying events and a number of components responsible for handling specific event types. Quite often there are separate components implementing the protocol logic specific to different roles that a node can play, e.g. leader and follower, or modes of operation, e.g. synchronization and normal operation. It is also common to separate different logical stages of the protocol, e.g. creating a proposal, validating a proposal, finalizing the decision. Another common pattern is to have a separate class of component responsible for maintaining state for each of the remote peers the node communicates with.</p>
<p>Some implementations go further and introduce smaller components, e.g. encapsulating the state of each individual proposal or representing the logic of counting votes and determining if there is a sufficient quorum. Nevertheless, there still remain components that are too complicated and hard to follow, so this modularity cannot be considered fine. To combat complexity, we need to learn how to achieve fine modularity.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="decomposition">Decomposition<a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#decomposition" class="hash-link" aria-label="Direct link to Decomposition" title="Direct link to Decomposition">​</a></h4>
<p>As one can cut bricks at different angles, so one can decompose components into sub-components in different ways. One way is to focus on the <em>operational</em> aspects, i.e. on how the pieces of implementation are going to be executed. With this approach, components would be primarily organized around actual data and control flow. This has a profound effect on the structure of the implementation.</p>
<p>Focusing on the operational aspects, protocol implementations will tend to be represented as stateful components, or as collections of stateful components, reacting to external events. This naturally induces applying the object-oriented approach to structuring the whole implementation, in which the protocol logic is mostly expressed as modifying pieces of component's state in response to <em>individual</em> inbound events and optionally producing new outbound events.</p>
<p>Although pieces of functionality tend to imply some state, individual events in a distributed system mostly happen as logical consequences of some other, causally related events in the scope of a larger <em>distributed</em> process. Thus structuring the implementation around event handling might <em>not</em> help to clearly express the overall protocol logic.</p>
<p>The way we approach decomposition also greatly impacts such properties of code as <a href="https://en.wikipedia.org/wiki/Coupling_(computer_programming)" target="_blank" rel="noopener noreferrer"><em>coupling</em></a> and <a href="https://en.wikipedia.org/wiki/Cohesion_(computer_science)" target="_blank" rel="noopener noreferrer"><em>cohesion</em></a>, i.e. the degree of interdependence between different components and the strength of relationship between the elements inside components, respectively. Loose coupling and high cohesion are generally desirable.</p>
<p>Failing to recognize the significance of implicit logical connections and properly express them often causes higher degree of coupling between components, i.e. entanglement. It is particularly important to distinguish essential and incidental complexity here. Sometimes complications, such as <em>circular dependencies</em>, may occur naturally and represent essential features of the protocol logic, e.g. <em>recursiveness</em>. For example, some internal events should often be treated, for the most part, the same way as equivalent external events. This can be achieved by looping those events back for handling in the protocol implementation.</p>
<p>Organizing components in a more structured way helps to manage dependencies between them, e.g. they can be arranged in <em>layers</em> or <em>hierarchically</em>, chained together in <em>pipelines</em>, etc. For example, in the Algorand implementation, the core logic of the consensus protocol is structured as a hierarchical state machine. The layered approach is well exemplified in the  <a href="https://docs.rs/tower/0.4.12/tower/" target="_blank" rel="noopener noreferrer"><code>tower</code></a>&nbsp;networking library, which is used by the Sui implementation. In the Apache ZooKeeper implementation, client requests are processed using a pipeline of&nbsp;request processing components chained together.</p>
<p>The amount of mutable internal state maintained by components also matters. Making components more static can often help to simplify the implementation. For example, in the Sui implementation, most of the consensus-specific components are static in terms of consensus configuration, i.e. instead of supporting reconfiguration directly in those components, they are simply recreated upon reconfiguration.</p>
<p>Many components require certain <em>context</em> or <em>environment</em>, i.e. they depend on some common piece of state or functionality like information about prior communication with the remote peer, access to persistent storage, diagnostic logging, etc. This is usually accomplished by capturing references to the environment inside the component or passing it explicitly. In functional programming, one can represent the environment with a <a href="https://en.wikipedia.org/wiki/Monad_(functional_programming)" target="_blank" rel="noopener noreferrer">monadic</a> interface. Some programming languages provide special features for that purpose, e.g. <a href="https://docs.scala-lang.org/tour/implicit-parameters.html" target="_blank" rel="noopener noreferrer">contextual parameters in Scala</a>. Interacting with the context from withing a component should be convenient but clearly constrained by the component's interface.</p>
<p>We would like to possibly avoid <em>fragmentation</em> of the core logic and facilitate <em>local reasoning</em> so that it is easier to reason about correctness, especially when introducing changes, without being too much concerned about larger scopes. We need to shift the focus more onto the <em>functional</em> and <em>logical</em> aspects, i.e. what the pieces of implementation achieve and how they ensure the desired outcome, so that the protocol implementation better reflects causal dependencies and logical connections.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="composability">Composability<a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#composability" class="hash-link" aria-label="Direct link to Composability" title="Direct link to Composability">​</a></h4>
<p>Even a highly modular implementation is not necessarily highly <a href="https://en.wikipedia.org/wiki/Composability" target="_blank" rel="noopener noreferrer"><em>composable</em></a>, i.e. allowing to easily recombine and reuse its components. It is hard to reuse components that are not composable. Moreover, composability has huge transformative potential: unlocking true power of expressiveness and flexibility, we can push the limits and uncover a new dimension of possibilities for finding better solutions, whether to fix a flaw in an existing implementation or to design and implement something completely new.</p>
<p>Composability primarily emerges from the properties of individual components and the way they can be combined together. It demands components that are not only loosely coupled, but <em>generic</em> as well. It also requires <em>unified</em> means of abstraction and combination that satisfy certain properties, such as <a href="https://en.wikipedia.org/wiki/Closure_(mathematics)" target="_blank" rel="noopener noreferrer">closure</a> and <a href="https://en.wikipedia.org/wiki/Associative_property" target="_blank" rel="noopener noreferrer">associativity</a>, while preserving principal properties of individual components in combination.</p>
<p>All of the explored code bases were meant to implement only a specific protocol or a close family of protocols, except Substrate, which is supposed to support a wide range of protocols. Most of the implementations define abstract interfaces for major components, employing various forms of <a href="https://en.wikipedia.org/wiki/Polymorphism_(computer_science)" target="_blank" rel="noopener noreferrer">polymorphism</a>, and apply the <a href="https://en.wikipedia.org/wiki/Dependency_inversion_principle" target="_blank" rel="noopener noreferrer">dependency inversion principle</a>. This makes components replacable and can help to reduce coupling. Being able to replace a component allows using alternative implementations of the component, e.g. for unit testing. However, most of those dependency inversion interfaces seem to only make sense within a very specific, predefined structure of the whole implementation, i.e. they are mostly about decomposing rather than recomposing. Truly composable components, on the other hand, are those that can be put together in an open-ended range of new, surprising combinations.</p>
<p>Though there are some examples of composability used in the explored code bases. The communication layer in the Sui implementation takes advantage of the layered design of &nbsp;<a href="https://github.com/MystenLabs/anemo" target="_blank" rel="noopener noreferrer"><code>anemo</code></a>, a peer-to-peer networking library based on <a href="https://docs.rs/tower/0.4.12/tower/" target="_blank" rel="noopener noreferrer"><code>tower</code></a>: it processes RPC requests from other nodes through pipelines composed out of&nbsp;<code>tower</code>&nbsp;middleware layers provided by the&nbsp;<code>anemo</code>&nbsp;library. The state machine representing the core logic of the consensus protocol in the Algorand implementation consists of uniformly defined event handlers organized in a hierarchy of event routers dispatching events to the corresponding handler.</p>
<p><a href="https://en.wikipedia.org/wiki/Asynchrony_(computer_programming)" target="_blank" rel="noopener noreferrer">Asynchrony</a> and <a href="https://en.wikipedia.org/wiki/Concurrency_(computer_science)" target="_blank" rel="noopener noreferrer">concurrency</a> make achieving composability particularly challenging. Components implemented using usual concurrent programming techniques based on <a href="https://en.wikipedia.org/wiki/Lock_(computer_science)" target="_blank" rel="noopener noreferrer">lock-based</a> synchronization primitives fall short of composability: a simple combination of individually absolutely correct components may easily fail to ensure consistency or cause a deadlock. Ensuring correctness in this model often requires breaking abstractions and dealing with synchronization directly in an awkward and error-prone way. Alternative concurrent programming techniques, such as <a href="https://en.wikipedia.org/wiki/Software_transactional_memory" target="_blank" rel="noopener noreferrer">software transactional memory</a> (STM) used in the Cardano implementation, can help to overcome these issues without compromising on modularity and composability. More on asynchrony and concurrency in the next section.</p>
<p>Functional programming places a significant emphasis on composability. One of its core principles is to break down programs into smaller, reusable functions, avoiding side effects, that can be easily combined to create more complex functionality. This encourages a more <em>declarative notation</em>, which often results in code that is easier to reason about. The approaches and techniques employed in functional programming, such as <a href="https://en.wikipedia.org/wiki/Immutable_object" target="_blank" rel="noopener noreferrer">immutability</a>, <a href="https://en.wikipedia.org/wiki/Lazy_evaluation" target="_blank" rel="noopener noreferrer">lazy evaluation</a>, <a href="https://en.wikipedia.org/wiki/Monad_(functional_programming)" target="_blank" rel="noopener noreferrer">monads</a> and <a href="https://en.wikipedia.org/wiki/Effect_system" target="_blank" rel="noopener noreferrer">effect systems</a>, etc., are therefore a great source of ideas for enhancing composability.</p>
<p>Composability is indispensable for <em>future-proof</em> software solutions. Though this property doesn't necessarily emerge together with modularity; conversely, achieving it may be challenging, especially in the inherently concurrent context of distributed systems. Therefore, we should approach this proactively and deliberately design for composability.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="concurrency">Concurrency<a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#concurrency" class="hash-link" aria-label="Direct link to Concurrency" title="Direct link to Concurrency">​</a></h3>
<p><a href="https://en.wikipedia.org/wiki/Concurrent_computing" target="_blank" rel="noopener noreferrer">Concurrent programming</a> is a way to structure code into multiple <em>threads of control</em>—concurrent tasks—that can execute concurrently. Observable effects caused by individual tasks can interleave in concurrent execution. Understanding and reasoning about code in concurrent programming requires a more complex mental model compared to sequential programming. Perhaps, <em>nondeterminism</em> is the main source of complexity in concurrent programming: concurrent programs can produce different results depending on the exact timing of external events and task execution.</p>
<p>Concurrent programming is known to be error prone. Concurrent tasks accessing shared resources generally require some form of coordination. Depending on the available mechanisms for interaction and communication between concurrent tasks, there may be different methods of coordinating them and controlling concurrency, e.g. <a href="https://en.wikipedia.org/wiki/Lock_(computer_science)" target="_blank" rel="noopener noreferrer">lock-based synchronization primitives</a>, <a href="https://en.wikipedia.org/wiki/Message_passing" target="_blank" rel="noopener noreferrer">message passing</a>, and <a href="https://en.wikipedia.org/wiki/Software_transactional_memory" target="_blank" rel="noopener noreferrer">software transactional memory</a>. However, properly applying those methods in a nontrivial system often becomes complicated and requires great deal of care. When concurrent tasks happen to <em>interfere</em> with each other in unanticipated ways, subtle issues, such as&nbsp;<a href="https://en.wikipedia.org/wiki/Race_condition#In_software" target="_blank" rel="noopener noreferrer">race conditions</a>,&nbsp;<a href="https://en.wikipedia.org/wiki/Deadlock" target="_blank" rel="noopener noreferrer">deadlocks</a>, and&nbsp;<a href="https://en.wikipedia.org/wiki/Starvation_(computer_science)" target="_blank" rel="noopener noreferrer">resource starvation</a>, may start manifesting themselves.</p>
<p>Concurrent programs with mutable memory shared between threads can suffer from <a href="https://en.wikipedia.org/wiki/Race_condition#Data_race" target="_blank" rel="noopener noreferrer"><em>data races</em></a>. A data race is basically a situation where one thread accesses a memory location whereas another thread can simultaneously perform a conflicting write to that memory location. Preventing data races is not only important to avoid memory corruption; this can also significantly simplify the mental model.</p>
<p>Normally, we can assume <a href="https://en.wikipedia.org/wiki/Sequential_consistency" target="_blank" rel="noopener noreferrer">sequential consistency</a> in concurrent programs that are free of data races. In essence, a sequentially consistent execution of a concurrent program must be equivalent to <em>some</em> <em>sequential</em> execution, respecting the order and semantics of operations specified in the program. So such executions are linear schedules, each representing a possible concurrent interleaving of the program.</p>
<p>Execution schedules that only differ in the interleaving of operations local to threads of execution, i.e. operations not visible to other threads or externally, are effectively equivalent. Therefore, the number of possible distinct schedules depends on the number of <em>non-local</em> operations in the execution, i.e. operations used to communicate between threads or cause externally visible effects, and it grows exponentially.</p>
<p>Concurrent programming is an effective model of computation, but it is more complex and requires an appropriate approach in order to avoid subtle concurrency issues. Data face freedom is a particularly desired property since it simplifies the model providing sequential consistency. Under that model, reducing the number of non-local operations can greatly help to further simplify reasoning about the concurrent program.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="approaches-to-concurrency">Approaches to Concurrency<a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#approaches-to-concurrency" class="hash-link" aria-label="Direct link to Approaches to Concurrency" title="Direct link to Approaches to Concurrency">​</a></h4>
<p>Programming languages support different approaches to concurrency; they provide different features and different concurrency mechanisms in their runtimes and ecosystems. The explored code bases are written in the following languages: Java, Go, Rust, and Haskell. Let's have a look at how those code bases approach concurrency, depending on the choice of programming language.</p>
<p>The code bases written in traditional mainstream languages like Java tend to achieve concurrency by explicitly spawning <a href="https://en.wikipedia.org/wiki/Thread_(computing)#Kernel_threads" target="_blank" rel="noopener noreferrer"><em>OS threads</em></a>, which communicate through <em>shared mutable memory</em> and synchronize with <a href="https://en.wikipedia.org/wiki/Lock_(computer_science)" target="_blank" rel="noopener noreferrer"><em>lock-based primitives</em></a>. Those implementations are normally structured into objects exposing thread-safe methods to interact with them concurrently. This approach is well known and established in the industry; it is therefore <em>widely supported</em> in the ecosystems built around those languages. Newer system programming languages like Rust usually provide support for this approach, as well.</p>
<p>This low-level approach gives the programmer a <em>high level of control</em> as it directly reflects how concurrency is actually achieved by the system. On the other hand, it requires a lot of care since properly using low-level synchronization primitives together is tricky and <em>error prone</em>. Moreover, OS threads are relatively <em>expensive</em>, and, therefore, building highly concurrent programs by frequently spawning short-living threads on demand is impractical. Instead, programs are often organized into a small number of long-running threads; though using thread pools can help to achieve more flexibility. Most importantly, as mentioned before, concurrent components synchronized with the lock-based primitives suffer from <em>poor composability</em>.</p>
<p>The Go language has built-in support for concurrency based on <a href="https://en.wikipedia.org/wiki/Computer_multitasking#Preemptive_multitasking" target="_blank" rel="noopener noreferrer">preemptive multitasking</a> with lightweight <a href="https://en.wikipedia.org/wiki/Thread_(computing)#User_threads" target="_blank" rel="noopener noreferrer">user threads</a> called <em>goroutines</em>. It encourages <em>message-passing</em> style of communication and synchronization between goroutines through blocking, optionally buffered FIFO <em>channels</em>; though it also supports traditional lock-based synchronization. The built-in <a href="https://go.dev/ref/spec#Select_statements" target="_blank" rel="noopener noreferrer"><code>select</code> statement</a> can be used to combine several channel operations in order to perform a single pseudo-randomly selected operation that is ready to proceed; unless there is a default case, the <code>select</code> statement blocks until at least one of the operations can proceed.</p>
<p>The <code>select</code> statement in Go allows <em>composing</em> multiple potentially blocking operations on channels into a single operation. For that reason, some of the explored code bases, e.g. SmartBFT-Go, occasionally use Go channels in place of traditional lock-based synchronization primitives in order to combine them with channel operations in a single <code>select</code> statement.</p>
<p>Go does not restrict access to <em>shared mutable data</em> by concurrent goroutines, so <em>data races</em> are still possible. Go provides quite <em>limited control</em> over the runtime managing execution of goroutines, thus making fine-tuning and controlling concurrent execution difficult.</p>
<p>The Rust language emphasizes safety without sacrificing performance. Thanks to the <a href="https://doc.rust-lang.org/book/ch04-00-understanding-ownership.html" target="_blank" rel="noopener noreferrer">ownership model</a> and strong type system, it can effectively ensure at compile time that the code is <em>free of data races</em>. Being a system programming language, Rust supports concurrent programming with OS threads and shared memory, which are useful to optimize performance and for implementing other styles of concurrency, such as message passing. Rust's ownership and type system features prevent accidental sharing of mutable state between threads.</p>
<p>The explored code bases written in Rust primarily rely on the <a href="https://en.wikipedia.org/wiki/Asynchrony_(computer_programming)" target="_blank" rel="noopener noreferrer">asynchronous</a> programming features of Rust to achieve concurrency. Async Rust can be seen as a form of <a href="https://en.wikipedia.org/wiki/Cooperative_multitasking" target="_blank" rel="noopener noreferrer">cooperative multitasking</a> where asynchronous, non-blocking computations are represented with the <a href="https://docs.rs/futures/latest/futures/future/trait.Future.html" target="_blank" rel="noopener noreferrer"><code>Future</code></a> trait (interface). Rust futures are <em>passive</em>, i.e. they have to be actively driven by <em>polling</em> in order to make progress.</p>
<p>Ultimately, asynchronous code in Rust requires some <em>executor</em> function that can drive a future by polling it to completion. There is an open-ended <em>choice of async runtimes</em> in the Rust ecosystem, which provide executors. <a href="https://tokio.rs/" target="_blank" rel="noopener noreferrer">Tokio</a> is one of the most widely used runtimes in the Rust ecosystem; all of the explored code bases written in Rust are based on it. One can create <em>specialized runtimes</em>, e.g. Sui has a simulator that provides an drop-in replacement for Tokio and supports deterministic, randomized execution.</p>
<p>The <a href="https://en.wikipedia.org/wiki/Async/await" target="_blank" rel="noopener noreferrer">async/await syntax</a> in Rust helps writing asynchronous fragments of code very close to normal, synchronous code. The <code>async</code> keyword introduces an <em>async context</em> by constructing a future from the corresponding piece of code; the <code>await</code> expression can be used within an async context to poll another future and yield control if that future is not yet ready to produce a value.</p>
<p>Apart from using the async/await syntax, Rust futures can be <em>composed</em> together using various combinators provided by the <a href="https://docs.rs/futures/latest/futures/" target="_blank" rel="noopener noreferrer"><code>futures</code></a>, <a href="https://docs.rs/tokio/latest/tokio/" target="_blank" rel="noopener noreferrer"><code>tokio</code></a>, and other crates. In particular, the <code>select</code> macro allows polling multiple futures simultaneously until one of them completes, similar to the <code>select</code> statement in Go; the&nbsp;<code>join</code>&nbsp;macro polls multiple futures to completion. There are also asynchronous channels for asynchronously producing a sequence of values and streams for communication between asynchronous tasks.</p>
<p>Asynchronous Rust is evolving rapidly; thus, it may still lack maturity, has limited documentation and less-established best practices. Many developers find programming in asynchronous Rust quite challenging and sometimes counter-intuitive, e.g. when dealing with cancellation, long-running or blocking operations, and due to the passive nature of futures. Although Rust prevents some concurrency problems like data races, concurrent code is still vulnerable to different types of concurrency bugs (e.g., deadlocks, logic errors, etc.) and requires deep understanding and careful design.</p>
<p>Finally, concurrency in Haskell is based on lightweight <a href="https://en.wikipedia.org/wiki/Thread_(computing)#User_threads" target="_blank" rel="noopener noreferrer">user threads</a>. Haskell allows throwing asynchronous exceptions from one thread to another. Handling asynchronous exceptions safely requires great care in <a href="https://en.wikipedia.org/wiki/Critical_section" target="_blank" rel="noopener noreferrer">critical sections</a>, i.e. when manipulating shared resources. Since Haskell is a <a href="https://en.wikipedia.org/wiki/Purely_functional_programming" target="_blank" rel="noopener noreferrer">purely functional</a> programming language, it does not explicitly support shared mutable memory for communication between threads. One of the mechanisms for normal communication between Haskell threads is <a href="https://hackage.haskell.org/package/base-4.19.0.0/docs/Control-Concurrent-MVar.html" target="_blank" rel="noopener noreferrer"><code>MVar</code></a>, a synchronizing variable, which can act as a synchronized container for shared state or as a one-place channel. Concurrent Haskell <em>prevents data races</em>, but using <code>MVar</code>s is susceptible to other concurrency bugs, such as race conditions, deadlocks, etc.</p>
<p>Another mechanism for concurrent communication widely used in the Haskell ecosystem is <a href="https://en.wikipedia.org/wiki/Software_transactional_memory" target="_blank" rel="noopener noreferrer">Software Transactional Memory</a> (STM). STM is an <a href="https://en.wikipedia.org/wiki/Optimistic_concurrency_control" target="_blank" rel="noopener noreferrer">optimistic concurrency</a> mechanism that allows transactions over shared mutable variables (transactional variables or&nbsp;<a href="https://hackage.haskell.org/package/stm-2.5.2.1/docs/Control-Concurrent-STM-TVar.html" target="_blank" rel="noopener noreferrer"><code>TVar</code></a>s) to be <em>safely composed</em> and&nbsp;<a href="https://hackage.haskell.org/package/stm-2.5.2.1/docs/Control-Monad-STM.html#v:atomically" target="_blank" rel="noopener noreferrer">atomically executed</a>, without exposing the implementation details. STM transactions can&nbsp;<a href="https://hackage.haskell.org/package/stm-2.5.2.1/docs/Control-Monad-STM.html#v:retry" target="_blank" rel="noopener noreferrer">block</a>&nbsp;on an <em>arbitrary</em> condition; alternative STM transactions can be composed together using the&nbsp;<a href="https://hackage.haskell.org/package/stm-2.5.2.1/docs/Control-Monad-STM.html#v:orElse" target="_blank" rel="noopener noreferrer"><code>orElse</code></a>&nbsp;combinator. The Haskell type system ensure that STM transactions cannot have undesired side effects and thus are safe to roll back and retry.</p>
<p>Building various custom concurrency abstractions and combinators with STM is relatively easy and safe, thanks to <em>high composability</em>. For instance, in Cardano, concurrent components expose STM transactions for retrieving relevant pieces of their mutable current state; the components then interact by combining and atomically executing such STM queries from other components and atomically updating the corresponding pieces of their own mutable state.<sup><a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#user-content-fn-modular-concurrency-with-stm-d8d72b" id="user-content-fnref-modular-concurrency-with-stm-d8d72b" data-footnote-ref="true" aria-describedby="footnote-label">4</a></sup></p>
<p>However, STM has some limitations and caveats. First of all, <em>composable</em> <em>multi-way</em> communication between threads cannot be expressed in STM. That is because STM transactions cannot produce a visible side effect while being blocked. This is closely related to another limitation: STM does not provide <em>fairness</em> for threads waiting in a blocked STM transaction. In contrast, <code>MVar</code>s guarantee fair scheduling of threads blocked on the same <code>MVar</code>. STM also incurs some overhead in terms of memory and performance costs, which depends on the size of transactions. Though sometimes it can actually help building more efficient mechanisms. Long-running STM transactions can suffer from starvation, i.e. being repeatedly rolled-back and retried. Finally, Haskell, similar to Go, provides quite limited control over its runtime.</p>
<p>To summarize, the traditional mainstream approach to concurrency based on explicit, low-level synchronization primitives and communication directly through shared mutable memory is well known and established, but it is tricky, error prone, and suffers from poor composability. Restricting concurrent access to shared memory, e.g. with the ownership model as in Rust or immutability as in Haskell, can help preventing data races. Communication and synchronization through message passing primitives like channels and using combinators like select can improve composability. Spawning short-lived OS threads may be too expensive; thread pools and lightweight user thread runtimes can help to achieve more flexibility. Though relying on a concurrency runtime is an additional dependency that is not always replacable or adjustable. Another approach to concurrency with good flexibility and composability is asynchronous programming with cooperative multitasking and async/await syntax, as exemplified by Rust. Software transactional memory is a highly composable and flexible approach to concurrency, though it has some restrictions, additional overhead and does not guarantee fairness.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="evading-concurrency">Evading Concurrency<a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#evading-concurrency" class="hash-link" aria-label="Direct link to Evading Concurrency" title="Direct link to Evading Concurrency">​</a></h4>
<p>Given all the challenges with concurrent programming, why not trying to avoid concurrency as much as possible? Some of the explored code bases go quite far this route and implement almost all of the core protocol logic as a <em>completely sequential state machine</em>, perhaps only offloading long-running operations (e.g., computationally intensive cryptography) to dedicated concurrent execution pools. Let's consider consequences of this approach.</p>
<p>First of all, distributed systems are <em>inherently concurrent</em> because they, by definition, consist of multiple nodes running largely independently. Thus, each node needs to handle events (e.g., messages received over the network or expired timeouts) originating from different sources <em>asynchronously</em>, i.e. independent of its main program flow and handling of events from other sources. Moreover, the protocol logic must also reflect the concurrent nature of the system.</p>
<p>So some parts of the protocol are fundamentally sequential, e.g. delivering totally ordered transactions, whereas some parts are fundamentally concurrent, e.g. handling of messages received over the network from different peer nodes. Some parts <em>may</em> be concurrent, but don't have to, e.g. validation of the subsequent messages while finishing processing of the current one.</p>
<p>Attempting to implement an essentially concurrent part of the protocol in a sequential manner, i.e. without using concurrent programming techniques, necessarily requires explicitly maintaining and switching contexts. Not only this adds some amount of boilerplate code and makes it entangled, more importantly, this causes <em>fragmentation</em> of the core protocol logic because such an artificially sequential component still has to multiplex handling of asynchronous events. Therefore, what in concurrent programming could have been naturally expressed as a blocking operation becomes an abrupt return of control, breaking out of the sequential component.</p>
<p>There is another problem with multiplexed handling of asynchronous events in sequential code, namely controlling the flow of events from concurrent sources. Consider a situation where a sequential component is given an event to handle that it cannot yet fully process because, in order to make a decision on how to react to the event, it first needs to handle some other events, e.g. it has to complete the current round of the protocol before participating in a new one. Since the sequential component cannot block waiting and has to return the control back, there are basically two options: dropping the event or putting it aside into some kind of buffer. In the first case, the event source cannot assume that all events it emits will be reliably handled and has to take this into account in its logic, e.g. emit an equivalent event under some conditions later. In the second case, there should be some way to enforce a reasonable bound on the amount of buffered pending events without compromising the protocol properties, e.g. emitting further events only after having received an acknowledgement from the destination. This can add a lot more complexity to the protocol implementation.</p>
<p>So concurrency cannot be easily evaded in distributed systems. Attempting to avoid using concurrent programming techniques complicates the implementation and causes fragmentation of the protocol logic in code. On the other hand, when done appropriately, designing for concurrency and using concurrent programming techniques can actually be advantageous. It boils down to recognizing inherently concurrent and sequential parts of the protocol and finding appropriate ways to express this distinction in code. Those parts of the protocol that are neither inherently concurrent nor sequential may nevertheless benefit from being implemented as concurrent: Designing for concurrency can guide towards better decoupling of components while concurrent execution can help to achieve higher responsiveness and performance.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="nondeterminism">Nondeterminism<a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#nondeterminism" class="hash-link" aria-label="Direct link to Nondeterminism" title="Direct link to Nondeterminism">​</a></h3>
<p>As mentioned in the previous section, distributed systems are inherently concurrent and therefore nondeterministic. If we think of nondeterminism in terms of events happening in the system then it can manifest itself as unpredictable events or their order. For example, requests from external agents (clients, users, etc.), values produced by a random-number generator, or node failures are not known in advance; the same set of messages may arrive at different nodes in different order due to unpredictable delays in communication; timeouts may happen due to unexpectedly long delays. Inner workings of nodes can introduce additional, implementation-specific nondeterminism, e.g. unspecified order of iteration over unordered collections, scheduling of concurrent tasks, etc. To some extend, the purpose of distributed protocols can be seen as confining nondeterminism within certain constraints in order to maintain the required invariants.</p>
<p>Nondeterministic steps in protocol execution introduce alternative state transitions, thus expanding the <a href="https://en.wikipedia.org/wiki/State_space_(computer_science)" target="_blank" rel="noopener noreferrer"><em>state space</em></a>. This complicates reasoning about distributed protocols, as well as implementing and verifying them, because it often requires considering a large number of possible executions. Nondeterministic execution also makes <em>reproducing</em> problems and debugging particularly challenging. Therefore, it is desirable to control nondeterminism or attempt to eliminate it.</p>
<p>Some of the explored code bases constrain nondeterminism by implementing parts of the protocol as <em>deterministic</em> state machines. Inherently nondeterministic aspects, such as time, randomness, and asynchronous operations, are abstracted out of those state machines. Randomness, as well as current time, can be supplied to the state machine through abstract interfaces provided as dependencies. Alternatively, the current timestamp can be supplied to the state machine at each step explicitly in the input. Time can also be represented in terms of an abstract logical clock maintained by the state machine, which is then advanced with special tick events periodically supplied to the state machine. Asynchronous operations can be requested by the state machine by emitting special output events; the result is then supplied back as special input events. This approach is very close to evading concurrency discussed before and therefore is associated with the same kind of disadvantages.</p>
<p>In Haskell, as a strictly typed purely functional programming language, ordinary functions are deterministic (<a href="https://en.wikipedia.org/wiki/Referential_transparency" target="_blank" rel="noopener noreferrer">referentially transparent</a>) in the mathematical sense: given the same input, they must produce the same result. Nondeterministic computations are expressed using the <a href="https://en.wikipedia.org/wiki/Monad_(functional_programming)" target="_blank" rel="noopener noreferrer">monadic</a> interface. Only IO actions, when executed in the&nbsp;<a href="https://hackage.haskell.org/package/base-4.19.0.0/docs/GHC-IO.html#t:IO" target="_blank" rel="noopener noreferrer">IO monad</a>, can cause side effects and produce nondeterministic results. This is enforced by the type system. Cardano takes advantage of this by making most of its code polymorphic in the main IO-like monad. This allows fully controlling nondeterminism by choosing the main monad implementation.</p>
<p>Being able to control nondeterminism is particularly useful for testing and debugging. This allows creating <em>reproducible</em> test environments, as well as <a href="https://en.wikipedia.org/wiki/Discrete-event_simulation" target="_blank" rel="noopener noreferrer">discrete-event simulation</a>&nbsp;for faster-than-real-time simulation of time delays. For example, Cardano uses a simulation environment for the IO monad that closely follows core Haskell packages; Sui has a simulator based on&nbsp;<a href="https://github.com/madsim-rs/madsim" target="_blank" rel="noopener noreferrer"><code>madsim</code></a> that provides an API-compatible replacement for the&nbsp;<a href="https://tokio.rs/" target="_blank" rel="noopener noreferrer">Tokio</a> runtime and intercepts various POSIX API calls in order to enforce determinism. Both allow running the same code in production as in the simulator for testing.</p>
<p>Nondeterminism is an important aspect of distributed systems, so it should be clearly expressed in the implementation. Type system features can help with that. Confining nondeterminism within <em>natural</em> boundaries of components can reduce complexity and simplify reasoning about the protocol implementation. Simulated execution of unmodified code with controlled nondeterminism is a very effective technique in testing and debugging.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="communication">Communication<a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#communication" class="hash-link" aria-label="Direct link to Communication" title="Direct link to Communication">​</a></h3>
<p>Communication is at the core of distributed systems where individual nodes need to coordinate in order to act as a coherent system. Nodes in a distributed system interact with each other by exchanging <em>peer-to-peer</em> (P2P) messages. The communication happens over an <em>unreliable</em> network medium that only provides <em>best-effort, unordered delivery</em> of data packets, i.e. it may fail to deliver individual packets or deliver them out of order. Moreover, nodes can fail, and, in general, it may be impossible to determine precisely if a peer node has failed or its messages were simply dropped or delayed in the network. Nodes can also differ in processing power and experience different traffic load. Therefore, it is important to manage the rate of data transmission using <a href="https://en.wikipedia.org/wiki/Flow_control_(data)" target="_blank" rel="noopener noreferrer"><em>flow control</em></a> mechanisms, as well as to retransmit lost pieces of data. This can contribute significantly to the overall complexity of distributed protocols and their implementation.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="communication-layers">Communication Layers<a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#communication-layers" class="hash-link" aria-label="Direct link to Communication Layers" title="Direct link to Communication Layers">​</a></h4>
<p>Most of the explored implementations use SSL/TLS over TCP/IP as a transport layer for P2P communication. Establishing a TCP connection takes a few packet round trips over the network. Moreover, operating systems impose limits on the number of open TCP connections per process because they consume system resources. For those reasons, communication layers based on TCP establish long-lived connections with remote peers and try to keeps the number of open connections low. This often means that the transport-level connections have to be <em>multiplexed</em> into multiple logical sub-streams.</p>
<p>Substrate and Lighthouse use <a href="https://libp2p.io/" target="_blank" rel="noopener noreferrer"><code>libp2p</code></a> as a networking stack for communication between nodes. The <code>libp2p</code>  framework is a versatile modular peer-to-peer networking stack. It provides a collections of abstractions, mechanisms, and protocols for facilitating communication in P2P systems. In particular, <code>libp2p</code> supports multiple transport mechanisms (TCP, QUIC, WebSocket, WebTransport, etc.), encryption schemes (TLS and Noise), and stream multiplexing. Higher-level protocols in <code>libp2p</code> are implemented on top of reliable, ordered, bidirectional binary streams, which are transparently encrypted and multiplexed by the framework.</p>
<p>Communication layer in Sui is based on&nbsp;<a href="https://github.com/MystenLabs/anemo" target="_blank" rel="noopener noreferrer"><code>anemo</code></a>, a peer-to-peer networking library built on top of&nbsp;<a href="https://en.wikipedia.org/wiki/QUIC" target="_blank" rel="noopener noreferrer">QUIC</a>. QUIC is a modern higher-level network transport protocol layered over UDP. It has built-in support for encryption and multiplexing. Similar to TCP connections, QUIC streams are reliable, ordered, bidirectional, providing flow control (backpressure), but they are cheap and almost instantaneous to open once an initial connection is established. The <code>anemo</code> library takes advantage of the efficient stream-multiplexing capability of QUIC; <code>libp2p</code> also uses the built-in capabilities of QUIC when it is used as a transport mechanism.</p>
<p>So there may be several levels of communication abstractions. There are low-level transport protocols like UDP or TCP, medium-level ones like QUIC, and comprehensive high-level networking stacks like <code>libp2p</code>. Higher-level mechanisms can be built on top of lower-level layers. Sometimes, it makes sense to fuse several layers, e.g. QUIC efficiently embeds security into the transport layer. In order to simplify implementation of higher-level layers, it is desirable to take advantage of those properties that are already guaranteed by lower-level layers, e.g. reliable, ordered delivery and flow control provided by commonly used transport layers such as TCP and QUIC.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="styles-of-communication">Styles of Communication<a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#styles-of-communication" class="hash-link" aria-label="Direct link to Styles of Communication" title="Direct link to Styles of Communication">​</a></h4>
<p>There are different ways to organize communication between nodes. The most common styles of communication in the explored code bases are <em>request-response</em> and <em>fire-and-forget</em> message delivery. The <em>request-response</em> style follows the remote procedure call (RPC) pattern: the initiator node sends a message to the remote node, and the latter is expected to respond back. In the fire-and-forget style, the initiator node unidirectionally sends messages to the remote node without waiting for a response. Another style of communication, which is also often used in the explored implementations, is <em>gossiping</em>, where nodes publish and disseminate pieces of information among themselves in an indirect and random manner. Cardano uses a <em>session-based</em> style of communication, where peers establish continuous bidirectional communication channels and exchange messages according to some stateful communication protocol.</p>
<p>The <em>fire-and-forget</em> message delivery is a very simple style of communication. It does not mandate any acknowledgement from the remote node, so it can only provide best-effort delivery guarantee. Messages that cannot be handled for any reason are often simply dropped, e.g. when a message queue is full. Usually, there is also no guarantee about ordering of messages. Higher-level code needs to take care of such things as flow control, retransmission of lost messages, as well as determining and maintaining the context to handle messages in. On the other hand, this style can be expressed with a non-blocking interface. That allows sending a message to a group of remote nodes at once, which is a simple form of best-effort multi-/broadcasting. Some implementations provide a blocking or asynchronous variant of the interface giving more control over data flow within the local node. For example, in Substrate, the sender should wait until it acquires a free slot in the outgoing message buffer; the slot reservation is then consumed to enqueue a message.</p>
<p>The <em>request-response</em> style is a simple type of session-based communication: sending a request initiates a new session, which normally terminates with reception of the corresponding response. Sessions can terminate abnormally, e.g. upon a timeout. The request-response style demands blocking or asynchronous interface on the sender side since it should wait for and handle the eventual response or error. This provides a context for response messages linking them to the corresponding requests. However, the communication layer treats each individual session independently. More complex patterns of interaction have to be split into a number of one-shot request-response sessions. Multiple sessions may be initiated concurrently, and the communication layer needs to keep track of those one-shot sessions starting, running, and finishing concurrently.</p>
<p>The <em>session-based</em> style of communication is connection-oriented and supports <em>stateful</em> interaction between nodes. Communication sessions are established between individual nodes and represent reliable, ordered, bidirectional message streams. This provides a context for the messages being exchanged between nodes and implies blocking or asynchronous interface. Thanks to reliable and ordered delivery, the context establishes causal relationship between individual messages. Relying on those assumptions can greatly simplify the protocol implementation while taking advantage of the guarantees commonly provided by stream-based transport layers. This style of communication is quite generic and can express many different patterns of interaction. Combined with built-in flow control (backpressure), it is particularly suited for implementing <em>consumer-driven</em> communication. On the other hand, session-based communication cannot directly express multi-/broadcasting primitives and can induce additional latency in certain patterns of interaction. Though higher-level communication mechanisms built on top of session-based communication can implement multi-/broadcasting, whereas using <a href="https://en.wikipedia.org/wiki/Protocol_pipelining" target="_blank" rel="noopener noreferrer">pipelining</a> techniques can help to hide latency and achieve good performance.</p>
<p>The <em>gossip-style</em> communication designates probabilistic broadcasting in a relay network of nodes. It resembles the best-effort broadcasting in the fire-and-forget message delivery style. The key difference is that data in the gossip-style communication can propagate from one node to another in multiple hops rather than being received directly from the source node. This makes it suitable for sparsely connected networks. Therefore, gossip communication can scale well in large networks. It can provide, with high probability, eventual delivery of bounded amount of data under normal network conditions. This style of communication implies a publish-subscribe interface. Similar to the fire-and-forget message delivery, the interface is largely stateless and can be non-blocking. Under the hood, it is often implemented using the advertise-request-response pattern of communication: nodes advertise available pieces of data to their neighbors and exchange with them the missing parts following the request-response pattern. Efficient gossip implementations require adaptive network topology and advanced data dissemination techniques, which can make them fairly complicated.</p>
<p>An interesting example of using the gossip-style communication is artifact pools in the Internet Computer blockchain. Artifact pools in ICP are structured collections of artifacts, generic pieces of data produced by the local replica or received from other nodes. The gossip layer is responsible for synchronizing artifact pools between nodes. Nodes communicate with each other through the artifact pools by adding/removing/moving artifacts to/from/between pool sections. Higher-level code is responsible for artifact validation; it also determines retention and prioritization policies.</p>
<p>It is easy to notice that some styles of communication can be implemented in terms of others. So the request-response style is a reduced from of the session-based communication, which is more generic and expressive. Both can be implemented relying on the fire-and-forget delivery and using some message retransmission and acknowledgement protocol. Or conversely, the fire-and-forget message delivery can be implemented on top of a reliable session-based communication using bounded lossy message queues. Similarly, gossip mechanisms can be implemented using any of the other styles of communication; though the implementations may differ in complexity.</p>
<p>Different styles of communication have different properties that can significantly influence the shape of code built around them. Some of them are strictly more expressive than others, but do not necessarily reduce to an equivalent, because less expressive mechanisms may have more efficient implementations. In order to avoid accidental complexity when implementing distributed protocols, it is important to have a range of communication mechanisms with aligned interfaces and clearly defined properties.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="internal-communication">Internal Communication<a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#internal-communication" class="hash-link" aria-label="Direct link to Internal Communication" title="Direct link to Internal Communication">​</a></h4>
<p>Apart from interaction between nodes, there is also communication between concurrent tasks within the same node. This internal communication shares some similarity with communication between nodes. The main difference is in the communication medium: while different nodes communicate through unreliable and slow network, internal communication happens through fast and reliable shared memory. Some programming models and techniques make the similarity particularly prominent, e.g. the <a href="https://en.wikipedia.org/wiki/Actor_model" target="_blank" rel="noopener noreferrer">actor model</a>, <a href="https://en.wikipedia.org/wiki/Communicating_sequential_processes" target="_blank" rel="noopener noreferrer">communicating sequential processes</a> (CSP), <a href="https://en.wikipedia.org/wiki/Remote_procedure_call" target="_blank" rel="noopener noreferrer">remote procedure calls</a> (RPC), etc.</p>
<p>Any piece of shared memory can act as a communication channel between internal components. Such a channel can be established by simply sharing a reference to the corresponding piece of memory. Internal messages do not need translation into/from a binary representation; they can be simply shared by reference. The request-response style of communication can be implemented as simple invocation of blocking or asynchronous procedures (functions); invoking non-blocking procedures (functions) without a return value corresponds to the fire-and-forget message delivery style. Obviously, such procedures need to be safe for concurrent invocation.</p>
<p>The session-based communication style can be implemented for internal communication using the constructs commonly known as <a href="https://en.wikipedia.org/wiki/Channel_(programming)" target="_blank" rel="noopener noreferrer"><em>channels</em></a> (e.g. <a href="https://go.dev/ref/spec#Channel_types" target="_blank" rel="noopener noreferrer">channels</a> in Go, <a href="https://docs.rs/tokio/latest/tokio/sync/index.html#message-passing" target="_blank" rel="noopener noreferrer">Tokio channels</a> in Rust) or concurrent <em>queues</em> (e.g. <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/LinkedBlockingQueue.html" target="_blank" rel="noopener noreferrer"><code>LinkedBlockingQueue</code></a> and other concurrent <a href="https://docs.oracle.com/javase/8/docs/api/java/util/Queue.html" target="_blank" rel="noopener noreferrer">queues</a> in Java). Those constructs belong to fundamental mechanisms of <em>communication and coordination</em> between concurrent components. Channels can be <em>buffered</em> or <em>unbuffered</em> (i.e. not buffered). Buffered channels and queues can hold items being sent through them without blocking the sender. In contrast, sending to or receiving from an unbuffered channel acts as a rendezvous point: it synchronizes the sender and the receiver at the point of communication.</p>
<p>Buffered channels and queues that can hold more than a singe item may return items to a receiver in different order. FIFO is the most commonly used ordering policy, in which items are returned in the same order as they were inserted. LIFO is another option, in which the most recently inserted item is the one that is returned first. One can think of many other options such as priority queues etc. The preferred ordering policy would depend on the purpose of communication.</p>
<p>Buffered channels and queues can be <em>bounded</em> or <em>unbounded</em>. The bounded version imposes a hard limit on the amount of items that they can hold. Unbounded channels and queues usually provide a simple <em>non-blocking</em> interface for inserting new items. However, they require some additional mechanism to prevent accumulating indefinite amount of items, e.g. blocking ingress of external events when internal buffers grow above certain threshold or relying on time-based assumptions such as throttling the data flow or imposing expiration time on the items. Such mechanisms can make reasoning about the protocol implementation more complicated.</p>
<p>Bounded channels and queues usually provide blocking or asynchronous interface. They can also support non-blocking insertion of new items, but then they must discard some items when there is no more capacity left. There may be different eviction policies. The simplest one is to discard the item being inserted. Otherwise, the new item is inserted, but some of the buffered items must be discarded, e.g. the least recently inserted one. Similarly to the ordering policy, there may be many other options, and the choice depends on the purpose of communication.</p>
<p>It is also worth mentioning buffered channels with a single-item buffer. They can be convenient for communicating a single item from one concurrent component to another, e.g. sending a response message back to the requester. The <a href="https://docs.rs/tokio/latest/tokio/sync/oneshot/index.html" target="_blank" rel="noopener noreferrer"><code>oneshot</code></a> channel in Tokio is a good example of such channel type. <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html" target="_blank" rel="noopener noreferrer"><code>CompletableFuture</code></a> in Java can also be considered a kind of single-item buffered channel, as well as synchronizing variables&nbsp;<a href="https://hackage.haskell.org/package/base-4.19.0.0/docs/Control-Concurrent-MVar.html" target="_blank" rel="noopener noreferrer"><code>MVar</code></a> and <a href="https://hackage.haskell.org/package/stm-2.5.2.1/docs/Control-Concurrent-STM-TMVar.html" target="_blank" rel="noopener noreferrer"><code>TMVar</code></a> in Haskell. Another interesting example of a single-item buffered channel is the <a href="https://docs.rs/tokio/latest/tokio/sync/watch/index.html" target="_blank" rel="noopener noreferrer"><code>watch</code></a> channel in Tokio: it always keeps the last value sent to it. The <code>watch</code> channel is useful for watching for changes to a value from multiple concurrent components. Transactional variables (<a href="https://hackage.haskell.org/package/stm-2.5.3.0/docs/Control-Concurrent-STM-TVar.html" target="_blank" rel="noopener noreferrer"><code>TVar</code></a>s) in Haskell are somewhat similar to watch channels since STM&nbsp;transactions can be suspended until one of the&nbsp;<a href="https://hackage.haskell.org/package/stm-2.5.2.1/docs/Control-Concurrent-STM-TVar.html" target="_blank" rel="noopener noreferrer"><code>TVar</code></a>s that it has read from has been updated.</p>
<p>Channels and queues often serve as fundamental constructs to implement <a href="https://en.wikipedia.org/wiki/Message_passing" target="_blank" rel="noopener noreferrer">message passing</a> between concurrent components. They can be used to implement various styles of internal communication and higher-level components. For example, implementations of components for communication between nodes often use channels and queues as internal message buffers.</p>
<p>The <a href="https://en.wikipedia.org/wiki/Publish%E2%80%93subscribe_pattern" target="_blank" rel="noopener noreferrer">publish-subscribe</a> design pattern resembles the gossip style of communication. It can be implemented for internal communication as an event bus or broadcast channel. Same as channels and queues, it can be buffered or unbuffered, bounded or unbounded. Unless messages can be dropped, unbuffered and bounded buffered implementations only support non-blocking publishing/broadcasting of messages if no subscriber blocks.</p>
<p>Similar to communication between nodes, different mechanisms and styles of internal communication have different properties that can significantly influence the shape of code. Therefore, it is equally important to have a range of internal communication mechanisms with aligned interfaces and clearly defined properties. The similarity between mechanisms for internal communication and communication between nodes provides an interesting perspective and can help to come up with better abstractions for communication.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="resilience">Resilience<a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#resilience" class="hash-link" aria-label="Direct link to Resilience" title="Direct link to Resilience">​</a></h3>
<p><em>Fault-tolerant</em> distributed systems are meant to tolerate (within limits) faults of individual nodes due to crashes, network partitioning, malfunctioning, or even malicious behavior. Crash fault tolerant (CFT) systems, e.g. Apache Kafka and Apache Zookeeper, are relatively simple since they can only withstand node crashes and network partitioning. Byzantine fault tolerant (BFT) systems, e.g. public blockchains, are designed to withstand arbitrary (including malicious) behavior of a fraction of nodes and thus are significantly more complicated. There are two sides of the issue: preventing faulty or malicious nodes from compromising the whole system and recovering failed nodes to rejoin the system.</p>
<p>Theoretically, fault-tolerant distributed protocols are designed so that they guarantee their safely and liveness properties despite the presence of faulty nodes in the system, provided that certain assumptions hold. In practice, those guarantees are only provided if the implementation ensures that the required assumptions actually hold. This is particularly challenging in BFT systems meant to operate in adversarial environments. Nodes in such systems can be subjects to various attacks, such as denial-of-service (DoS) attacks through resource exhaustion. <em>Fairness</em> between peers is another concern since it may also impact resilience.</p>
<p>To mitigate those risks, many implementations maintain <em>reputation</em> metrics for remote peers and apply <em>rate-limiting</em> or <em>throttling</em> techniques. Peer reputation is based on the observable behavior of the peer, such as protocol violations, timeouts, and performance. Nodes normally disconnect from remote peers whose reputation drops below a certain threshold, as well as reject inbound connections from those peers. Conversely, peers with higher reputation may be preferred for communication in sparsely connected systems.</p>
<p>In its threat-aware design approach, Cardano emphasizes <em>detecting protocol violations&nbsp;as early as possible</em> in the operational cycle where the data is available but&nbsp;the least resources have been expended&nbsp;to process the received data<sup><a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#user-content-fn-threat-aware-approach-d8d72b" id="user-content-fnref-threat-aware-approach-d8d72b" data-footnote-ref="true" aria-describedby="footnote-label">5</a></sup>. For instance, block and transaction relaying is&nbsp;interleaved&nbsp;with validation to avoid circulating invalid data in the system. This approach works well with <em>stateful</em> <em>consumer-driven</em> communication between nodes: Inbound messages must be well-formed syntactically and semantically valid&nbsp;in the context&nbsp;of information previously received from the peer node.</p>
<p>In order to allow failed nodes to efficiently restore and safely rejoin the system, some parts of the protocol state can be persisted in a stable storage. This is usually implemented as a <a href="https://en.wikipedia.org/wiki/Write-ahead_logging" target="_blank" rel="noopener noreferrer">write-ahead log</a> (WAL), an append-only&nbsp;stable storage used for crash recovery. Certain events are first recorded in the log before the corresponding actions are taken, e.g. before sending messages to other nodes. This allows the node to restore and continue participating in the protocol from where it stopped, without violating the protocol. Persistence mechanisms are also required to support recovery from a massive system crash, i.e. to provide the <a href="https://en.wikipedia.org/wiki/Durability_(database_systems)" target="_blank" rel="noopener noreferrer">durability</a> property.</p>
<p>Early detection of protocol violations is advantageous, and the implementation structure should allow that. There should be a clear path for propagating information about detected protocol violations and other anomalies to adjust peer reputation metrics and take appropriate measures. Persistence mechanisms, such as write-ahead logging, are required for durability, as well as for safe and efficient node recovery.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="optimization">Optimization<a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#optimization" class="hash-link" aria-label="Direct link to Optimization" title="Direct link to Optimization">​</a></h3>
<p>Practical distributed systems require not only reliability but also efficiency. Simplistic designs and implementations unfortunately tend to exhibit poor performance, whereas we would like that our systems scale well and provide decent <em>throughput</em> and <em>latency</em>. Improving those characteristics demands optimization at protocol and implementation levels. Great effort has been put into optimizing distributed protocols during decades of active research. This gave rise to a range of elaborate protocols attempting to achieve ever higher performance. On the implementation level, there also exists a variety of technical means for increasing efficiency. Optimizations, however, often add more complexity and make protocols harder to reason about and implement.</p>
<p>Protocol-level optimizations may involve using more complex communication patterns and topologies. Protocol phase <em>pipelining</em>, i.e. participating with a single message in multiple protocol phases at once, and <em>speculative execution</em> are common techniques to improve responsiveness. <em>Batching</em>, as well as advanced cryptography such as <a href="https://en.wikipedia.org/wiki/Threshold_cryptosystem" target="_blank" rel="noopener noreferrer">threshold signatures</a>, helps to reduce communication overhead. State-of-the-art protocols are often based on <em>advanced data structures</em>, such as <a href="https://en.wikipedia.org/wiki/Directed_acyclic_graph" target="_blank" rel="noopener noreferrer">directed acyclic graphs</a> (DAGs). At the implementation level, <em>on-demand execution</em> and <em>caching</em> are often used to avoid performing unnecessary or duplicate operations.</p>
<p>Communication contributes significantly to the overall overhead in distributed systems and, therefore, is a clear target for optimization. Point-to-point <a href="https://en.wikipedia.org/wiki/Protocol_pipelining" target="_blank" rel="noopener noreferrer">protocol <em>pipelining</em></a>, i.e. continuous sending of requests without waiting for the corresponding responses, can greatly increase performance by hiding high network latency. Widely used transport protocols, such as TCP, tend to perform best under <em>steady data flow</em>. Moreover, keeping multiple network connections consumes additional system resources. Therefore, implementations commonly <em>multiplex</em> multiple logical communication streams through a single network connection. Minimizing <a href="https://en.wikipedia.org/wiki/Head-of-line_blocking" target="_blank" rel="noopener noreferrer"><em>head-of-line blocking</em></a> effects may require <em>flow control</em> mechanisms at the level of individual logical streams; large pieces of data should be transmitted through a multiplexed connection <em>in chunks</em>. Specific kinds of communication, e.g. state synchronization in blockchain systems, can benefit from dedicated, specialized communication mechanisms.</p>
<p>Interaction between concurrent components and across levels of abstraction is also subject to fine-tuning and optimization. <em>Prioritization</em> and flexible <em>policies</em> can help to maximize performance. For example, the system may perform better when certain concurrent tasks or communication paths have higher priority. Internal communication, as well as communication between nodes, may be optimized through prioritization and retention policies applied to individual messages or kinds of messages. This sort of optimization requires deep understanding of the protocol and its  inner workings.</p>
<p>Expensive low-level operations, such as spawning threads, blocking on locks, and copying data, can become a hidden cause of suboptimal performance. There are well-known techniques that can help to avoid unnecessary low-level overhead. For example, <a href="https://en.wikipedia.org/wiki/Thread_pool" target="_blank" rel="noopener noreferrer"><em>execution pools</em></a> avoid the overhead associated with creation and destruction of threads for executing short-lived concurrent tasks; <a href="https://en.wikipedia.org/wiki/Non-blocking_algorithm" target="_blank" rel="noopener noreferrer"><em>non-blocking algorithms</em></a> can improve performance by avoiding unnecessary suspension of thread execution; <a href="https://en.wikipedia.org/wiki/Zero-copy" target="_blank" rel="noopener noreferrer"><em>zero-copy</em></a> techniques focus on eliminating excessive copying of data.</p>
<p>Improving performance characteristics of distributed systems may require nontrivial changes in the underlying protocols and their implementations. The structure of the code should be flexible enough to support such changes. Some optimizations can be confined within boundaries of abstract components, whereas some may require crossing the borders of modularity. <em>Flexible</em> and <em>composable</em> primitives and interfaces <em>designed for optimization</em> would help to fully realize the potential of distributed systems in practice.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="correctness">Correctness<a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#correctness" class="hash-link" aria-label="Direct link to Correctness" title="Direct link to Correctness">​</a></h2>
<p>Correctness is absolutely essential for implementation of distributed fault-tolerant protocols since they are critical for ensuring reliability of the whole system. <a href="https://en.wikipedia.org/wiki/Formal_verification" target="_blank" rel="noopener noreferrer"><em>Formal verification</em></a> methods allow confirming protocol correctness in terms of desired properties. Applying those methods requires that the protocol is described precisely with a <a href="https://en.wikipedia.org/wiki/Formal_specification" target="_blank" rel="noopener noreferrer"><em>formal specification</em></a>. Though the way protocols are actually implemented in code tends to be significantly different from the notation used in protocol specifications. This discrepancy is clearly a potential source of errors. There are different methods that can help to acquire higher confidence in correctness of the protocol implementation.</p>
<p>Testing is an established practice to examine correctness of software. Comprehensive testing of complex systems happens at different levels, and modularity of the code supports more effective testing by isolating functionalities, enabling independent unit testing, simplifying integration testing, and promoting code reuse. Some code bases include <em>dedicated interfaces</em> and <em>hooks</em> to facilitate testing; <a href="https://man.freebsd.org/cgi/man.cgi?query=fail" target="_blank" rel="noopener noreferrer"><em>fail points</em></a> is a technique that allows injecting errors and other behavior at runtime for testing purposes, which is used in Aptos and Sui. In Algorand, each&nbsp;component of the hierarchical state machine implementing the consensus protocol can perform <em>pre- and post-condition checks</em> to validate if it conforms to its contract. Most code bases perform diagnostic <em>logging</em> or <em>tracing</em> that can also be useful for testing, e.g. to check invariants in property-based testing.</p>
<p><em>Deterministic <a href="https://en.wikipedia.org/wiki/Discrete-event_simulation" target="_blank" rel="noopener noreferrer">discrete-event simulation</a></em> is a powerful technique that can be used for performing <em>randomized</em> but <em>reproducible</em> testing. For example, Sui, Apache Kafka, and Cardano employ this technique. It works by running the code within a special runtime that supports deterministic, randomized execution of concurrent code, as well as faster-than-real-time simulation of time delays. This technique can be used to run an entire network in a single process, with <em>simulated network</em> latency and packet loss. To ensure deterministic execution, the simulation approach usually requires that the code is generic over the sources of local time and randomness; it can also rely on code instrumentation techniques. The key advantage of this approach is that it allows running precisely the same code in the simulator for testing as in production.</p>
<p>Certain correctness properties of code can be ensured statically, i.e. at compile time. Those checks rely on the programming language's type system. Software engineers can take advantage of <em>type safety</em> features to implement components in a way that makes them <em>safe by construction</em>. For example, Cardano uses the&nbsp;<a href="https://github.com/input-output-hk/typed-protocols/tree/typed-protocols-0.1.0.5" target="_blank" rel="noopener noreferrer"><code>typed-protocols</code></a>&nbsp;package, a generic framework for implementing application-level protocols, which is based on a simple form of&nbsp;<a href="https://en.wikipedia.org/wiki/Session_type" target="_blank" rel="noopener noreferrer">session typing</a>.<sup><a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#user-content-fn-typed-protocols-talk-d8d72b" id="user-content-fnref-typed-protocols-talk-d8d72b" data-footnote-ref="true" aria-describedby="footnote-label">6</a></sup> Within this framework, protocols are described as state machines encoded into Haskell types. The allowed transitions between states correspond to messages exchanged between the peers, so the protocol state determines which messages are allowed to be sent or must be accepted when received, at type level. This simplifies protocol implementation, allows early detection of protocol violations, and makes the protocols themselves deadlock-free by construction. More advanced type-level programming techniques may allow achieving impressive levels of type safety; however, such code may be significantly harder to implement, understand, and maintain.</p>
<p>Ensuring correctness in distributed systems is a complex task. Protocols and their properties can be formally specified and verified. Expressing the protocol specification and its implementation using possibly similar notations could help to ensure equivalence between the two. Modular and generic structure of code, as well as using various testing support features within the code base, support more effective testing. Supporting deterministic discrete-event simulation is particularly powerful for reproducible randomized testing. Finally, type safety techniques like session types and typestates can eliminate certain kinds of programming errors at compile time.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="resource-utilization">Resource Utilization<a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#resource-utilization" class="hash-link" aria-label="Direct link to Resource Utilization" title="Direct link to Resource Utilization">​</a></h2>
<p>Real computing systems are fundamentally bounded in the amount of available resources. Computers operate with limited computational power, memory, storage, and network bandwidth. Operating systems impose further limits on such system resources as threads, open network connections, file handles, etc. Practical systems are required to prevent <a href="https://en.wikipedia.org/wiki/Resource_leak" target="_blank" rel="noopener noreferrer">resource leaks</a>, as well as to ensure fair and efficient utilization of available resources.</p>
<p>Some resources, such as allocated memory, open file handles and network connections, spawned concurrent tasks and threads, may require explicit actions to release them properly when they are no longer needed. Failing to release resources promptly is known as a resource leak. It can cause <a href="https://en.wikipedia.org/wiki/Resource_starvation" target="_blank" rel="noopener noreferrer">resource starvation</a>, slowdowns, and instability in the system. Relying on explicit releasing of acquired resources is known to be error-prone. Automatically releasing resources based on <em>lifetimes</em> and <em>lexical scopes</em> is a more robust form of <a href="https://en.wikipedia.org/wiki/Resource_management_(computing)" target="_blank" rel="noopener noreferrer">resource management</a>. Sometimes the encompassing lexical scope's lifetime is longer than the resource's natural life cycle, e.g. when managing concurrent tasks, so that strict lexical scoping becomes inappropriate. In such cases, resources may be managed more explicitly within the scope, but with a fallback mechanism to track resources and ensure that any remaining resource gets released when leaving the scope.<sup><a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#user-content-fn-cardano-resource-registry-d8d72b" id="user-content-fnref-cardano-resource-registry-d8d72b" data-footnote-ref="true" aria-describedby="footnote-label">7</a></sup></p>
<p>Concurrency often makes resource management more challenging. First of all, concurrent tasks running in background is a kind of resource that needs to be released when no longer needed. Moreover, they can acquire other resources that should be released when the task is terminated, even in case of asynchronous cancellation. In simple cases, there is a limited number of long-running concurrent tasks, which are responsible for releasing the resources acquired by them, and their termination is synchronized with the main task; short-living jobs can run concurrently on execution pools that distribute those jobs among a number of long-running concurrent tasks. When more flexibility is desired, <a href="https://en.wikipedia.org/wiki/Structured_concurrency" target="_blank" rel="noopener noreferrer"><em>structured concurrency</em></a> can help managing concurrent code in a more organized and predictable manner by organizing concurrent tasks into a structured hierarchy with well-defined scopes and lifetimes.<sup><a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#user-content-fn-notes-on-structured-concurrency-d8d72b" id="user-content-fnref-notes-on-structured-concurrency-d8d72b" data-footnote-ref="true" aria-describedby="footnote-label">8</a></sup></p>
<p>Individual parts of a distributed system may operate at different pace. Moreover, for performance reasons, it is common to apply pipelining techniques when communicating with remote nodes, i.e. proceed without waiting for a response or acknowledgement form the remote node in order to hide network latency. Compensating for the delays and variability in throughput demands some kind of explicit or implicit buffering, e.g. buffered channels, send/receive queues, pending request trackers, out-of-context message buffers, etc. The amount of buffered state tends to grow under certain conditions, e.g. under heavy load or during network instability. Therefore, there should be some mechanisms to prevent <em>unbounded growth of state</em> without compromising liveness. That can be such mechanisms as backpressure, rate limiting, item expiration and eviction policies, etc.</p>
<p>In adversarial environments, potential DoS attacks through <em>resource exhaustion</em> is a major threat. An adversary may attempt to exhaust node's resources, such as network bandwidth, memory and computational capacity. In order to effectively mitigate such attacks, they should be prohibitively expensive for the attacker relative to the amount of resource consumed from honest participants. <em>Early detection of protocol violations</em> and <em>consumer-driven data flow</em>, as employed in Cardano, can reduce the amount of resources expended by the nodes under attack. It may also be useful to tack resource expenditure caused by processing messages from remote peers, as done in Avalanche, and apply <em>fair throttling</em> to communication channels.</p>
<p>Proper resource management is indispensable in long-running systems. It can be particularly challenging combined with concurrency. Reliable resource management approaches, e.g. based on lifetimes and lexical scopes, as well as structured concurrency, should be, when applicable, preferred to relying on explicit hand-coded releasing of acquired resources. Potential growth of state due to buffering requires mechanisms for ensuring bounded memory usage. Resource exhaustion attacks should be anticipated in adversarial environments and mitigated by minimizing their impact on honest nodes.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="maintainability">Maintainability<a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#maintainability" class="hash-link" aria-label="Direct link to Maintainability" title="Direct link to Maintainability">​</a></h2>
<p>Maintenance of distributed systems is challenging. Those systems are usually long-running critical parts of infrastructure with high reliability requirements. They are complex systems consisting of multiple nodes, often operated independently by different entities. Publicly available deployments are also subject to malicious attacks. Thus effective maintenance of distributed systems demands comprehensive mechanisms and tools.</p>
<p>First of all, deploying distributed systems may require specific <em>bootstrapping</em> procedures in order to ensure a secure setup for the whole system. Different distributed protocols may have different requirements and rely on different assumptions for the <em>setup phase</em>.<sup><a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#user-content-fn-decentralized-setup-assumptions-d8d72b" id="user-content-fnref-decentralized-setup-assumptions-d8d72b" data-footnote-ref="true" aria-describedby="footnote-label">9</a></sup> Protocol implementations should be clear about the requirements and assumptions for their setup phase. Long-running, highly available distributed systems should be capable of <em>upgrading</em> individual nodes with newer versions of the protocol implementation without disrupting the whole system. This requires designing for <em>backward and forward compatibility</em>. Similarly, failed nodes should be able to <em>recover</em> and <em>rejoin</em> the system safely and efficiently. Moreover, it is also desired that the system is able to safely recover from a massive crash, i.e. provide <a href="https://en.wikipedia.org/wiki/Durability_(database_systems)" target="_blank" rel="noopener noreferrer">durability</a>. Therefore, the protocols should be designed and implemented with a clear recovery procedure.</p>
<p>Distributed system administrators need mechanisms and tools for monitoring individual nodes in order to analyze the system and promptly detect anomalies. Developers also need effective mechanisms for analyzing, diagnosing issues, and identifying bugs in protocol implementations. <em>Logging</em>, <em>tracing</em>, and collecting <em>metrics</em> are common <em>observability</em> techniques to allow monitoring and obtaining diagnostic information from the system; most of the explored code bases use these techniques. <a href="https://opentelemetry.io/" target="_blank" rel="noopener noreferrer">OpenTelemetry</a> and <a href="https://prometheus.io/" target="_blank" rel="noopener noreferrer">Prometheus</a> are popular open-source monitoring solutions, which are used in many of the explored code bases.</p>
<p>Diagnostic logging typically refers to emitting and recording chronological <em>textual</em> messages that capture important events happening during the execution of software. Messages in diagnostic logs are traditionally assigned a severity level that can be used to disable logging of messages below a certain severity level, e.g. debug messages. Log messages can support addition of structured data along with a formatted text message, e.g. key-value context fields. Logging can be organized hierarchically, reflecting the structure of components within the system. Messages in <em>hierarchical logging</em> are usually automatically enriched with context from higher-level components.</p>
<p>Tracing is somewhat similar to logging, but it is focused on capturing a detailed view of the flow of execution in the system. Tracing records are primarily <em>structured</em> rather than textual and reflect <em>causal relationships</em>. In particular, <em>distributed tracing</em> is tracking of events caused by processing individual logical operations, such as user requests or transactions, across different components of a distributed system. A distributed trace is associated with a single logical operation and consists of spans linked with causal relationships where each span represents a particular activity within the operation. Spans normally contain structured data describing the corresponding activity and timing information.</p>
<p>Metrics represent numeric measurements that describe the system's behavior over time. Metrics are typically collected and aggregated at regular intervals. They can include various types of information such as CPU and memory utilization, latency, error rates, throughput, queue lengths, etc. There are different kinds or metrics; the most widely used are counter, gauge, and histogram. A counter is a cumulative metric monotonically increasing over time; a gauge expresses the current value of some measurement; a histogram records sampled observations in a statistical representation.</p>
<p>Observability is a&nbsp;<a href="https://en.wikipedia.org/wiki/Cross-cutting_concern" target="_blank" rel="noopener noreferrer" title="Cross-cutting concern">cross-cutting concern</a>. Most implementations define abstract interfaces for logging, tracing, and capturing metrics and require them as dependency across components; some use code instrumentation techniques. Cardano uses an interesting approach to implement observability features, called <em>contravariant tracing</em>, in which domain-specific values are provided to domain-agnostic processors. The <a href="https://en.wikipedia.org/wiki/Functor#Covariance_and_contravariance" target="_blank" rel="noopener noreferrer">contravariance</a> property allows domain-agnostic tracers to be adapted and stand in where a domain-specific tracer is required. This discourages using textual encoding for diagnostic logging/tracing in favor of dedicated domain-specific event types. Contravariant tracing can also be used to collect metrics.</p>
<p>Detailed logging and tracing can add significant overhead. When logging a large amount of diagnostic data is expensive, logging can be <em>sampled</em>, producing only a subset of the total messages based on a predetermined sampling rate or criteria. The contravariant tracing incurs zero runtime cost if the program is compiled with tracing disabled; this is possible even when dealing with a tracer which ignores only certain types of events.</p>
<p>Fault-tolerant distributed protocols should be designed and implemented with clear bootstrapping, upgrading, and recovery procedures. Note that upgradability relies on backward and forward compatibility of the implementation. It is also worth considering the durability feature, i.e. the ability to safely recover the system from a massive crash. There should be seamless support for usual observability and diagnostic mechanisms.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="flexibility">Flexibility<a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#flexibility" class="hash-link" aria-label="Direct link to Flexibility" title="Direct link to Flexibility">​</a></h2>
<p>Flexible software is able to adapt to changing requirements without having to undergo extensive restructuring. Flexibility is crucial for <em>adoption</em>, <em>reuse</em>, and <em>evolution</em> of code. Each explicit or implicit <em>assumption</em> or <em>requirement</em> imposed on how the code can be used is an additional <em>constraint</em> reducing flexibility. The explored code bases were primarily meant to implement particular protocols or serve specific purposes rather than to address fundamental needs for implementing distributed systems in general. This is a common approach to building software, but it tends to result in rather limited flexibility of the code.</p>
<p>In general, highly <em>modular</em> and <em>composable</em> code is also more flexible. Clear <a href="https://en.wikipedia.org/wiki/Separation_of_concerns" target="_blank" rel="noopener noreferrer"><em>separation of concerns</em></a> through abstract interfaces and <a href="https://en.wikipedia.org/wiki/Dependency_inversion_principle" target="_blank" rel="noopener noreferrer">dependency inversion</a> contributes to flexibility by enabling interchangeable components, as well as facilitating easier code modifications and extensions. Flexibility can also be enhanced with <em>generic</em> and <em>configurable</em> components. <a href="https://en.wikipedia.org/wiki/Generic_programming" target="_blank" rel="noopener noreferrer"><em>Generic programming</em></a> techniques, such as&nbsp;<a href="https://en.wikipedia.org/wiki/Parametric_polymorphism" target="_blank" rel="noopener noreferrer" title="Parametric polymorphism">parametric polymorphism</a>, encourage the development of more generic and adaptable components that can be used in different contexts without modification.</p>
<p>The ability to seamlessly integrate into larger systems is another aspect of flexibility required for adoption and reuse of protocol implementations. Since larger systems may opt for different programming languages and runtime environments, it is important to support interfacing with other languages and impose minimal runtime requirements. Rust is particularly suitable to implement robust software components for integrating into other languages and environments due to its rich language features, zero-cost abstractions, predictable performance, safe memory management without a garbage collector, and the ability to use custom concurrency runtimes.</p>
<p>Designing for flexibility promotes adoption, reuse, and evolution of code. Following this approach should be a deliberate choice from the beginning. Avoiding strong constraints, assumptions, and requirements, aiming at modularity and composability with generic and configurable components make for greater flexibility.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusions">Conclusions<a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#conclusions" class="hash-link" aria-label="Direct link to Conclusions" title="Direct link to Conclusions">​</a></h2>
<p>I learned a lot while exploring those 14 code bases. I have acquired a much deeper understanding of what is important for a practical distributed protocol implementation and what are the typical challenges there. I have seen different approaches in use and discovered some interesting ideas and techniques scattered around. Though I find the ways distributed protocols are implemented quite unsatisfactory. Even for an engineer experienced in implementing this kind of protocols, most of the the code bases were fairly hard to comprehend and follow. I can imagine how much effort it took and how painful was it to first make them work, as well as to improve them later.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="status-quo">Status Quo<a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#status-quo" class="hash-link" aria-label="Direct link to Status Quo" title="Direct link to Status Quo">​</a></h3>
<p>Most of the time, it was rather hard to follow the main protocol, its causal dependencies and logical connections in the code that was presumably structured focusing on the operational aspects, fragmented, entangled, and cluttered. Structuring the protocol implementation directly around simplistic communication mechanisms foregoing reliable and ordered delivery guarantees provided by the transport layers, expressing concurrency and synchronization explicitly in terms of low-level mechanisms based on shared mutable memory and lock-based primitives or attempting to evade concurrency in favor of sequential state machines, all seem to cause fragmentation of the protocol logic across the code base, shift the focus towards operational technicalities, and incur cluttering of the code with boilerplate and hand-coded flow control, context switching, resource management, etc. Invasive ad hoc optimizations, patches, and cross-cutting concerns also contribute to muddling the code. Often insufficient modularity, unclear structure, excessive coupling, and abundance of mutable state complicate the matter further. Using sophisticated techniques and lack of inline documentation present additional obstacles for understanding.</p>
<p>It seems barely possible to fully convince oneself that the majority of the implementations actually correspond closely to the original protocol and guarantee the claimed properties under unfavorable conditions. The way the protocols are expressed in code does not appear anything like formal specification. The ever-present possibility of such subtle issues as race conditions, deadlocks, resource starvation, and, in some languages, data races manifesting themselves in such complicated code bases does not add more confidence. Unconstrained nondeterminism and abundance of non-local operations result in state space explosion, making rigorous test-based verification infeasible. Only a few of the implementations support reproducible testing with deterministic discrete-event simulation of unmodified code.</p>
<p>It also seems unclear how many of the implementations would behave under certain high load conditions, e.g. under a denial-of-service attack. Protocol violations are not always optimally detected at early stages of processing incoming data; many implementations lack mechanisms for propagating information about detected anomalies towards lower communication layers in order to restrict communication with offending nodes. The majority of the implementations employ the push style of communication and forgo flow control mechanisms of transport layers, so individual remote nodes can potentially send arbitrary amounts of data that the receiving node has to deal with in time. Uncomfortably often there are unbounded buffers and queues with unclear mechanisms that could control growth of state. Unreliable explicit hand-coded resource management could cause resource leaks, including concurrent tasks dangling in background.</p>
<p>In terms of observability, most of the protocol implementations rely on simple logging with context fields and collect various metrics. However, this may not provide enough details and context for effective debugging and analysis of the protocol execution.</p>
<p>The explored code bases are quite specific to particular protocols, execution environments, and use cases. Modularity there is rather coarse and most of the components are not meant to be reused or recombined; tight coupling is also not rare. This harms adaptability and reusability of the code, making it inflexible.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="we-can-do-better">We Can Do Better<a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#we-can-do-better" class="hash-link" aria-label="Direct link to We Can Do Better" title="Direct link to We Can Do Better">​</a></h3>
<p>I think we can do much better. I think we should not waste our efforts reinventing the wheel over and over again and repeating mistakes. Builders better focus on implementing the functionality specific to their solutions without having to figure out how to approach implementing the tricky but critically important distributed protocols. There should be a framework that solves the problem of implementing distributed protocols once and for all, a framework reach with easy-to-use, reliable primitives and components that can be taken as is or mixed and matched as needed, a framework that guides towards robust and understandable code, a framework that supports analyzing, monitoring, testing, and debugging protocol implementations, a framework that is reasonably efficient and can be easily integrated into various environments.</p>
<p>The framework should guide away from incidental, non-essential complexity and allow expressing protocol implementations in clear and understandable code. Protocol implementations should be structured primarily focusing on functional and logical aspects with clear separation of concerns, operational technicalities and sophisticated techniques possibly hidden behind simple and clearly defined abstractions. Fine modularity of reasonably small and simple components expressed in more declarative notation with reduced number of non-local operations should facilitate local reasoning. Components should have minimal internal state, as well as clearly defined requirements, properties, and external dependencies.</p>
<p>Concurrency requires special attention since it is unavoidable, tricky, and can add a great deal of complexity, whereas designing for concurrency can be actually advantageous in terms of code structure and modularity. Working with concurrency should be possibly safe, easy, and efficient. Low-level concurrency mechanisms, such as OS threads, lock-based synchronization primitives, and shared mutable memory, should only be used for implementing the internals of higher-level, safer, and easier-to-use concurrency mechanisms, such as concurrency runtimes. Expressing concurrent parts of the protocol in code should feel as natural as expressing sequential ones. This can be achieved with syntactical means, abstractions, and a concurrency model that recognizes any causally independent operations as potentially concurrent.</p>
<p>Since communication interfaces can greatly affect the structure of code built around them, we need a range of communication mechanisms with aligned interfaces and clearly defined properties. There should be different levels of abstractions for communication. Higher levels should take advantage of the properties already guaranteed by lower-level layers, such as reliable, ordered communication channels with flow control provided by commonly used transport layers. Expressing communication in stateful sessions can help to express causal relationship between individual messages and greatly simplify protocol implementations. Similarity between internal and external communication can suggest better abstractions.</p>
<p>Flexibility is extremely important to make the framework applicable to an open-ended space of use cases. Therefore, we should by all means avoid strong constraints, assumptions, and requirements. The framework should support integration with different programming languages and runtime environments. Its components should be generic and configurable. It should also support backward and forward compatibility. Composability is critical for ensuring great adaptability, reusability, and evolvability. It requires unified means of abstraction and combination. Generic programming techniques, such as parametric polymorphism, can be used to make components generic; functional and asynchronous programming techniques can be great sources of ideas for enhancing composability, particularly with concurrency.</p>
<p>Correctness of distributed protocol implementations should be verifiable, in terms of both safety and liveness properties. Formal verification methods are able to provide rigorous assurance about correctness of protocols and their implementations. However, since formal verification involves exhaustively analyzing all possible states of a system, it may become infeasible for large and complex components. Fine modularity, components amenable to local reasoning, as well as reducing the number of non-local and nondeterministic operations, can help making formal verification more tractable. In order to maintain equivalence between a formally verified protocol specification and its implementation in code, the implementation should be expressed possibly close to the formal specification, preferably using an identical notation. Type safely techniques, such as ownership, typestates, session types, linear and uniqueness types, can greatly help to ensure correctness of the code by making it virtually safe by construction in terms of certain properties. Hybrid approaches combining formal verification with other testing methods can be used to achieve decently high assurance about correctness where purely formal methods become infeasible. Deterministic discrete-event simulation of unmodified code is a particularly powerful technique to complement other verification methods with randomized, reproducible testing. Confining nondeterministic aspects behind abstract interfaces in code and being able to control nondeterminism during simulation is the key for enabling reproducible testing.</p>
<p>Distributed protocols and their implementations should provide strong guarantees even under unfavorable conditions, especially those supposed to be deployed in adversarial environments. The framework should employ a reliable approach for resource management in concurrent code, e.g. based on lifetimes and lexical scopes, structured concurrency. There should be mechanisms for flow control preventing unlimited growth of state and ensuring bounded memory usage. The framework should emphasize threat-aware design. Potential impact of resource exhaustion (DoS) attacks should be minimized with early detection of protocol violations and propagating information about detected anomalies for maintaining peer reputation metrics and taking appropriate measures. For that reason, consumer-driven patterns of communication should be preferred. There should also be mechanisms for safe and efficient recovery of failed nodes from persistent storage. Supporting durability, i.e. safe recovery after a massive system crash, is also desirable.</p>
<p>Protocols and their implementations should be clear about bootstrapping and recovery requirements and procedures. Upgradability requires backward and forward compatibility. There should be seamless support for usual observability and diagnostic mechanisms, such as logging, tracing, and collecting metrics. It may also be useful to provide mechanisms for tracking resource expenditure caused by processing incoming data. In place of simple logging with context fields, it seems advantageous supporting structured distributed tracing using domain-specific trace event types. This kind of tracing could also be suitable for collecting metrics. It is important to minimize incurred overhead when tracing is disabled. Code instrumentation can help to avoid cluttering code with tracing boilerplate.</p>
<p>The framework should provide good performance and support various optimizations, such as speculative and on-demand execution, caching, flexible prioritization policies. To support protocol-level optimizations, the framework should allow expressing complex communication patterns. The communication layer should prevent such undesired effects as head-of-line blocking, optimize data flow and take advantage of the properties provided by the transport layers. Lightweight user threads and non-blocking algorithms allow achieving high concurrency without compromising efficiency. Zero-copy techniques can be used to eliminate unnecessary copying of data.</p>
<p>So we need a structured, yet flexible enough, approach guiding away from incidental complexity towards understandability, fine modularity, and composability. The framework's components should be generic and configurable, allowing local reasoning about the implementation. Expressing concurrency and communication abstractions should be safe and easy, structured and composable. We should be serious about correctness and resilience against unfavorable conditions. The framework should also cater for maintenance needs, provide great observability and diagnostic mechanisms. It should deliver decent performance and allow for various optimizations.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="next-steps">Next Steps<a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#next-steps" class="hash-link" aria-label="Direct link to Next Steps" title="Direct link to Next Steps">​</a></h2>
<p>Having explored those implementations of distributed protocol, now it became more clear to me what is worth focusing on while developing the Replica_IO framework. I define the following key areas of focus:</p>
<ul>
<li><em>simplicity</em>: making protocol implementations well structured and understandable;</li>
<li><em>flexibility</em>: keeping the framework adaptable, widely applicable, and evolvable;</li>
<li><em>reliability</em>: ensuring that protocol correctness is verifiable and the implementation is resilient;</li>
<li><em>efficiency</em>: allowing for various optimizations and delivering good performance;</li>
<li><em>maintainability</em>: catering for maintenance needs and providing great diagnostic mechanisms.</li>
</ul>
<p>Achieving all of that at once is obviously not realistic. Therefore, the primary focus will be initially put on simplicity, flexibility, and reliability, but without neglecting the remaining aspects. Of particular interest are the matters of structure and notation supporting composability in concurrency and communication mechanisms, as well as controlling nondeterminism.</p>
<p>Exploring distributed protocol implementations was the first phase of the initial state-of-the-art exploration. The next step is to select and examine some existing frameworks for developing distributed protocols in order to find out how they attempt to approach the problem and, perhaps, also discover some interesting techniques or ideas employed there. Then there are some potentially related concepts, approaches, and techniques worth looking into. The exploration tasks are tracked in the scope of <a href="https://github.com/replica-io/replica-io/issues/7" target="_blank" rel="noopener noreferrer">this issue</a> on GitHub.</p>
<p>Once the initial exploratory stage is over, it will be time to come up with key ideas concerning core principles that will guide the process of designing and implementing generic components within the framework (milestone <a href="https://github.com/replica-io/replica-io/milestone/1" target="_blank" rel="noopener noreferrer">M0.1</a>). Then those ideas will be developed into clearly formulated concepts (milestone&nbsp;<a href="https://github.com/replica-io/replica-io/milestone/2" target="_blank" rel="noopener noreferrer">M0.2</a>), their feasibility will be verified with code (milestone&nbsp;<a href="https://github.com/replica-io/replica-io/milestone/3" target="_blank" rel="noopener noreferrer">M0.3</a>). After that, prototype, MVP, and production versions of the framework will be developed and released (milestones &nbsp;<a href="https://github.com/replica-io/replica-io/milestone/4" target="_blank" rel="noopener noreferrer">M1</a>, &nbsp;<a href="https://github.com/replica-io/replica-io/milestone/5" target="_blank" rel="noopener noreferrer">M2</a>, and &nbsp;<a href="https://github.com/replica-io/replica-io/milestone/6" target="_blank" rel="noopener noreferrer">M3</a>).</p>
<p>It does not mean at all that exploration, ideation, and prototyping will not take place at later stages; the milestones simply define the framework's general level of maturity. The framework will continuously evolve and expand and at some point become a de facto standard for implementing critical fault-tolerant systems providing a growing collection of easy-to-use reliable and efficient distributed replication mechanisms.</p>
<!-- -->
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37">❤️</span>Supporting</div><div class="admonitionContent_BuS1">If you like the project and find it valuable, please <a href="https://github.com/sponsors/replica-io">support</a> its further development! 🙏</div></div>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</div><div class="admonitionContent_BuS1"><p>If you have any thought you would like to share or any question regarding this post, please add a comment <a href="https://github.com/orgs/replica-io/discussions/35" target="_blank" rel="noopener noreferrer">here</a>. You are also welcome to <a href="https://github.com/orgs/replica-io/discussions/new/choose" target="_blank" rel="noopener noreferrer">start a new discussion</a> or chime in to <a href="https://discordapp.com/invite/CzPfN75URD" target="_blank" rel="noopener noreferrer">our Discord</a> server.</p></div></div>
<!-- -->
<section data-footnotes="true" class="footnotes"><h2 class="anchor anchorWithStickyNavbar_LWe7 sr-only" id="footnote-label">Footnotes<a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#footnote-label" class="hash-link" aria-label="Direct link to Footnotes" title="Direct link to Footnotes">​</a></h2>
<ol>
<li id="user-content-fn-other-impl-d8d72b">
<p>If you know of some other implementation that I should have absolutely looked into for some reason, please let me know. <a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#user-content-fnref-other-impl-d8d72b" data-footnote-backref="" aria-label="Back to reference 1" class="data-footnote-backref">↩</a></p>
</li>
<li id="user-content-fn-thinking-complexity-d8d72b">
<p>Actually, incidental complexity can start creeping in even earlier, into the way we <em>think</em> about distributed systems, but let's not go into this here. <a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#user-content-fnref-thinking-complexity-d8d72b" data-footnote-backref="" aria-label="Back to reference 2" class="data-footnote-backref">↩</a></p>
</li>
<li id="user-content-fn-tendermint-liveness-fix-d8d72b">
<p>Zarko Milosevic, CTO at Informal Systems, <a href="https://www.youtube.com/watch?v=c4BQ7v-CQfk&amp;t=296s" target="_blank" rel="noopener noreferrer">tells</a> in his invited talk at <a href="https://research.protocol.ai/sites/consensusday23/" target="_blank" rel="noopener noreferrer">ConsensusDays&nbsp;23</a> how a small protocol change addressing a major issue resulted in months of implementation work on the Tendermint code base. <a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#user-content-fnref-tendermint-liveness-fix-d8d72b" data-footnote-backref="" aria-label="Back to reference 3" class="data-footnote-backref">↩</a></p>
</li>
<li id="user-content-fn-modular-concurrency-with-stm-d8d72b">
<p>In his talk "<a href="https://www.youtube.com/watch?v=qlAKyivFxGQ" target="_blank" rel="noopener noreferrer">Using STM for Modular Concurrency</a>", Duncan Coutts expands on the approach to concurrency employed by Cardano. <a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#user-content-fnref-modular-concurrency-with-stm-d8d72b" data-footnote-backref="" aria-label="Back to reference 4" class="data-footnote-backref">↩</a></p>
</li>
<li id="user-content-fn-threat-aware-approach-d8d72b">
<p>More about the threat-aware design approach in <a href="https://iohk.io/en/research/library/papers/introduction-to-the-design-of-the-data-diffusion-and-networking-for-cardano-shelley/" target="_blank" rel="noopener noreferrer">"Introduction to the design of the Data Diffusion and Networking for Cardano Shelley"</a>. <a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#user-content-fnref-threat-aware-approach-d8d72b" data-footnote-backref="" aria-label="Back to reference 5" class="data-footnote-backref">↩</a></p>
</li>
<li id="user-content-fn-typed-protocols-talk-d8d72b">
<p>The <code>typed-protocols</code> framework was presented in the talk "<a href="https://skillsmatter.com/skillscasts/14633-45-minute-talk-by-duncan-coutts" target="_blank" rel="noopener noreferrer">Well-Typed Communication Protocols</a>" by Duncan Coutts. <a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#user-content-fnref-typed-protocols-talk-d8d72b" data-footnote-backref="" aria-label="Back to reference 6" class="data-footnote-backref">↩</a></p>
</li>
<li id="user-content-fn-cardano-resource-registry-d8d72b">
<p><a href="https://github.com/input-output-hk/ouroboros-consensus/blob/release-ouroboros-consensus-0.8.0.0/ouroboros-consensus/src/ouroboros-consensus/Ouroboros/Consensus/Util/ResourceRegistry.hs#L80" target="_blank" rel="noopener noreferrer"><code>ResourceRegistry</code></a>&nbsp;used in Cardano is an example of a fallback mechanism based on lexical scoping for preventing resource leaks. <a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#user-content-fnref-cardano-resource-registry-d8d72b" data-footnote-backref="" aria-label="Back to reference 7" class="data-footnote-backref">↩</a></p>
</li>
<li id="user-content-fn-notes-on-structured-concurrency-d8d72b">
<p>Nathaniel J. Smith elaborates on structured concurrency in great detail in his blog post <a href="https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/" target="_blank" rel="noopener noreferrer">"Notes on structured concurrency, or: Go statement considered harmful"</a>. <a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#user-content-fnref-notes-on-structured-concurrency-d8d72b" data-footnote-backref="" aria-label="Back to reference 8" class="data-footnote-backref">↩</a></p>
</li>
<li id="user-content-fn-decentralized-setup-assumptions-d8d72b">
<p><a href="https://decentralizedthoughts.github.io/2019-07-19-setup-assumptions/" target="_blank" rel="noopener noreferrer">This post</a> discusses the setup phase in distributed systems. <a href="https://replica-io.dev/blog/2024/03/04/on-implementation-of-distributed-prtocols#user-content-fnref-decentralized-setup-assumptions-d8d72b" data-footnote-backref="" aria-label="Back to reference 9" class="data-footnote-backref">↩</a></p>
</li>
</ol>
</section>]]></content:encoded>
            <author>sergefdrv@replica-io.dev (Sergey Fedorov)</author>
            <category>technical</category>
            <category>overview</category>
            <category>long</category>
        </item>
        <item>
            <title><![CDATA[The Story Behind Replica_IO]]></title>
            <link>https://replica-io.dev/blog/2023/09/04/the-story-behind-replica_io</link>
            <guid>https://replica-io.dev/blog/2023/09/04/the-story-behind-replica_io</guid>
            <pubDate>Mon, 04 Sep 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[The Story Behind Replica_IO - an open-source framework for building practical distributed replication mechanisms.]]></description>
            <content:encoded><![CDATA[<p>This post tells how the Replica_IO project originated and explains the
motivation behind it.</p>
<!-- -->
<!-- -->
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="my-background">My Background<a href="https://replica-io.dev/blog/2023/09/04/the-story-behind-replica_io#my-background" class="hash-link" aria-label="Direct link to My Background" title="Direct link to My Background">​</a></h2>
<p>I'd like to start by tell you a bit about my professional background.
I'm a research engineer with quite some experience in software
engineering. I began working as a software engineer back in 2009.</p>
<p>First 7 years, I was mostly focused on developing low-level system
software: I worked with such things as Linux kernel, microcontrollers,
hardware emulation, and trusted execution. Back then, I particularly
enjoyed contributing to <a href="http://qemu.org/" target="_blank" rel="noopener noreferrer">Qemu</a>, a generic and
open-source machine emulator and virtualizer. My contribution included
enhancing emulation of the ARM platform and enabling multithreading
support in the generic binary translation engine</p>
<p>In 2016, I took a big leap and came into research and development in
the areas of blockchain, distributed and decentralized systems. Soon
enough, I became absolutely excited about this, and since then, I keep
expanding my knowledge and experience in that area, in particular,
designing and implementing distributed protocols. During that period,
apart from proprietary stuff, I worked on the following open-source
projects:</p>
<ul>
<li><a href="http://github.com/hyperledger-labs/minbft" target="_blank" rel="noopener noreferrer">MinBFT Hyperledger Lab</a> — an implementation of the MinBFT
consensus protocol as a pluggable component. I was the main author,
contributor, and maintainer of the project.</li>
<li><a href="http://github.com/filecoin-project/mir" target="_blank" rel="noopener noreferrer">Mir</a> — a framework for implementing, debugging, and analyzing
distributed protocols. My main contribution was implementation of
the checkpointing mechanism, protocol garbage collection, and
reproducible testing with simulated time.</li>
<li><a href="http://fil.space/#components" target="_blank" rel="noopener noreferrer">Interplanetary Consensus (IPC)</a> — a framework to enable
on-demand horizontal scalability of the Filecoin blockchain. My
main contribution was redesign and implementation of the atomic
cross-chain transaction execution protocol in Rust.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="implementing-distributed-protocols">Implementing Distributed Protocols<a href="https://replica-io.dev/blog/2023/09/04/the-story-behind-replica_io#implementing-distributed-protocols" class="hash-link" aria-label="Direct link to Implementing Distributed Protocols" title="Direct link to Implementing Distributed Protocols">​</a></h2>
<p>So much was I excited about distributed systems, but, after a while, I
started feeling like there's something fundamentally wrong in how we
usually design and implement them.</p>
<p>Distributed protocols are notoriously complex, and it took academia
significant effort to develop a solid theoretical foundation for them.
Due to inherent concurrency, the reasoning about distributed systems
is quite tricky, and there are lots of pitfalls where one gets trapped
pretty quickly, unless being extremely careful. Though, I find this
really fascinating because I particularly love digging deep and
thinking thoroughly.</p>
<p>However, the way distributed protocols are conventionally described on
paper makes it hardly possible to implement them correctly with
confidence; it's simply too far from the realities of software
engineering. Not only academic papers often neglect some details of
practical importance but also the language and notation used there,
they require nontrivial translation to the languages and patterns
commonly used in programming. Add there typical issues that come up
inevitably when programming concurrent systems, time pressure, and we
end up with a great mess that one can hardly comprehend and maintain.</p>
<p>Moreover, it seems like those engineers who get their hands dirty and
implement distributed protocols for practical use tend to jump in and
try applying whatever approach they were used to or that was implied
by the surrounding system. Although one can certainly learn a lot from
such experiments (and I'm doing that), it's generally waste of efforts
when one simply needs to get the thing reliably working. More than
that, since this kind of code is quite hard to get right, inevitable
mistakes creep into such implementations and lurk there unnoticed.
Even when some of those mistakes get revealed, individual projects are
usually too busy and too specific to keep following and effectively
learning from each other.</p>
<p>Having implemented a couple of distributed protocols myself, I find
this status quo deeply unsatisfactory, especially when it comes to
distributed replication mechanisms such as consensus protocols. After
all, they are supposed to ensure consistency and availability in such
critical computing systems as distributed coordination services,
distributed databases, and blockchain. There is an opinion that the
main obstacle to wider adoption of distributed, decentralized systems,
particularly those capable of tolerating arbitrary (Byzantine) faults,
is their requirement for additional resources and reduced performance.
While it's certainly true that high reliability doesn't come for free,
I think the concerns regarding complexity do actually matter a lot in
the end; it's simply hard to get it right.</p>
<p>I think decentralized Byzantine-fault tolerant mechanisms should
prevail in future computing systems and we can do a much better job
working towards that. I believe such complex problems can have neat
solutions, not only efficient, but also easy to use. Clearly,
discovering and developing such solutions does take quite some effort.
There must have been attempts to solve this problem, apparently not
very successful. But since I like to think of myself as someone
discovering smart solutions to hard problems, I'm not too scared; I'm
stubborn enough 😄</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="replica_io">Replica_IO<a href="https://replica-io.dev/blog/2023/09/04/the-story-behind-replica_io#replica_io" class="hash-link" aria-label="Direct link to Replica_IO" title="Direct link to Replica_IO">​</a></h2>
<p>So I was thinking about this for years, but never managed to find room
for seriously working on it. Suddenly, in February 2023, I was
affected by a lay-off in <a href="https://protocol.ai/" target="_blank" rel="noopener noreferrer">Protocol Labs</a> and had to
leave; by that time, I had worked with the company as a long-term
collaborator, a Research Engineer at the <a href="https://research.protocol.ai/groups/consensuslab/" target="_blank" rel="noopener noreferrer">ConsensusLab</a>
group, for almost a year. After a while, I realized that this is
actually a great chance to finally start working on what I was
dreaming of.</p>
<p>Initially, I thought I would just take a break and spend some time on
a hobby project. I already had a name for it — Replica_IO, which had
come to my mind a few months before, as I had been yet again thinking
about communication between replicas in a distributed replication
system. However, once I started asking myself about my real intention
behind this, I realized that it's much bigger than just playing with a
pet project: what I really want is to make a breakthrough in how
distributed systems are designed and implemented!</p>
<p>In March 2023, I decided to found the Replica_IO project and work on
it full time as an independent research engineer. Since I believe in
open source, open innovation and collaboration, I also wanted to make
it radically open and started developing it entirely in the open from
day one. I <a href="https://github.com/replica-io/replica-io/issues/2" target="_blank" rel="noopener noreferrer">described</a> the project's purpose, goals, and
approach, <a href="https://github.com/replica-io/replica-io/issues/3" target="_blank" rel="noopener noreferrer">created</a> its logo, <a href="https://github.com/replica-io/replica-io/issues/1" target="_blank" rel="noopener noreferrer">defined</a> the initial
roadmap, and started working on the <a href="https://github.com/replica-io/replica-io/milestone/1" target="_blank" rel="noopener noreferrer">first milestone</a>.</p>
<p>At the time of this writing, I'm <a href="https://github.com/replica-io/replica-io/issues/7" target="_blank" rel="noopener noreferrer">exploring</a> some relevant
state of the art, <a href="https://github.com/replica-io/replica-io/wiki/State-of-the-art-exploration" target="_blank" rel="noopener noreferrer">summarizing</a> the findings.
Approaching this in a systematic way lets me dive deeper into the
problem, form a more educated opinion, find some inspiration, and
ultimately come up with effective ideas for achieving the project's
key technical objectives.</p>
<p>I understand how ambitious the goals of this project are and that it
may take long time to get there, but I'm absolutely sure it is worth
the effort. I'm surprised how much attention the project has already
attracted and would like to see great experts from the relevant fields
become involved and help to make it real. I also count on getting enough
support for this initiative, and I'm grateful to those who have
already been helping 🙏</p>
<p>If you'd like to learn more about this project, please visit the
<a href="https://replica-io.dev/about">About</a> page and watch <a href="https://youtu.be/oJlryr6bMCo" target="_blank" rel="noopener noreferrer">this talk</a>.</p>]]></content:encoded>
            <author>sergefdrv@replica-io.dev (Sergey Fedorov)</author>
            <category>introduction</category>
            <category>announcement</category>
            <category>story</category>
        </item>
    </channel>
</rss>